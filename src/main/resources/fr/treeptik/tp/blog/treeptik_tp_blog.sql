-- phpMyAdmin SQL Dump
-- version 4.4.13.1deb1
-- http://www.phpmyadmin.net
--
-- Client :  localhost
-- Généré le :  Mar 01 Mars 2016 à 10:48
-- Version du serveur :  5.6.28-0ubuntu0.15.10.1
-- Version de PHP :  5.6.11-1ubuntu3.1

SET FOREIGN_KEY_CHECKS=0;
SET SQL_MODE = "NO_AUTO_VALUE_ON_ZERO";
SET time_zone = "+00:00";


/*!40101 SET @OLD_CHARACTER_SET_CLIENT=@@CHARACTER_SET_CLIENT */;
/*!40101 SET @OLD_CHARACTER_SET_RESULTS=@@CHARACTER_SET_RESULTS */;
/*!40101 SET @OLD_COLLATION_CONNECTION=@@COLLATION_CONNECTION */;
/*!40101 SET NAMES utf8mb4 */;

--
-- Base de données :  `treeptik_tp_blog`
--
CREATE DATABASE IF NOT EXISTS `treeptik_tp_blog` DEFAULT CHARACTER SET latin1 COLLATE latin1_swedish_ci;
USE `treeptik_tp_blog`;

DROP TABLE IF EXISTS `Article`;
DROP TABLE IF EXISTS `Author`;
DROP TABLE IF EXISTS `Category`;
DROP TABLE IF EXISTS `Comment`;


CREATE TABLE IF NOT EXISTS `Author` (
  `id` bigint(20) NOT NULL,
  `Admin` tinyint(1) NOT NULL,
  `email` varchar(255) DEFAULT NULL,
  `password` varchar(255) DEFAULT NULL,
  `firstName` varchar(255) DEFAULT NULL,
  `lastName` varchar(255) DEFAULT NULL,
  `url` varchar(255) DEFAULT NULL
) ENGINE=InnoDB AUTO_INCREMENT=7 DEFAULT CHARSET=latin1;

CREATE TABLE IF NOT EXISTS `Category` (
  `id` bigint(20) NOT NULL,
  `name` varchar(255) DEFAULT NULL,
  `url` varchar(255) DEFAULT NULL
) ENGINE=InnoDB AUTO_INCREMENT=5 DEFAULT CHARSET=latin1;

CREATE TABLE IF NOT EXISTS `Article` (
  `id` bigint(20) NOT NULL,
  `content` longtext,
  `pubDate` datetime DEFAULT NULL,
  `published` tinyint(1) NOT NULL,
  `subTitle` longtext,
  `title` varchar(255) DEFAULT NULL,
  `author_id` bigint(20) DEFAULT NULL,
  `category_id` bigint(20) DEFAULT NULL
) ENGINE=InnoDB AUTO_INCREMENT=11 DEFAULT CHARSET=latin1;

CREATE TABLE IF NOT EXISTS `Comment` (
  `id` bigint(20) NOT NULL,
  `content` longtext,
  `email` varchar(255) DEFAULT NULL,
  `name` varchar(255) DEFAULT NULL,
  `pubDate` datetime DEFAULT NULL,
  `validated` tinyint(1) NOT NULL,
  `article_id` bigint(20) DEFAULT NULL
) ENGINE=InnoDB AUTO_INCREMENT=9 DEFAULT CHARSET=latin1;


--
-- Contenu de la table `Article`
--

INSERT INTO `Article` (`id`, `content`, `pubDate`, `published`, `subTitle`, `title`, `author_id`, `category_id`) VALUES
(1, 'Lets start\r\nLets   know  the status of the  machine\r\n\r\nServer    =   Centos 7\r\nIP = 192.168.183.129\r\n[root@storage-unixmen ~]# fdisk  -l \r\nDisk /dev/sda: 32.2 GB, 32212254720 bytes, 62914560 sectors\r\nUnits = sectors of 1 * 512 = 512 bytes\r\nSector size (logical/physical): 512 bytes / 512 bytes\r\nI/O size (minimum/optimal): 512 bytes / 512 bytes\r\nDisk label type: dos\r\nDisk identifier: 0x00047725\r\n   Device Boot      Start         End      Blocks   Id  System\r\n/dev/sda1   *        2048     1026047      512000   83  Linux\r\n/dev/sda2         1026048    62914559    30944256   8e  Linux LVM\r\nDisk /dev/sdb: 5368 MB, 5368709120 bytes, 10485760 sectors\r\nUnits = sectors of 1 * 512 = 512 bytes\r\nSector size (logical/physical): 512 bytes / 512 bytes\r\nI/O size (minimum/optimal): 512 bytes / 512 bytes\r\nDisk /dev/mapper/centos-root: 29.5 GB, 29490151424 bytes, 57597952 sectors\r\nUnits = sectors of 1 * 512 = 512 bytes\r\nSector size (logical/physical): 512 bytes / 512 bytes\r\nI/O size (minimum/optimal): 512 bytes / 512 bytes\r\nDisk /dev/mapper/centos-swap: 2147 MB, 2147483648 bytes, 4194304 sectors\r\nUnits = sectors of 1 * 512 = 512 bytes\r\nSector size (logical/physical): 512 bytes / 512 bytes\r\nI/O size (minimum/optimal): 512 bytes / 512 bytes\r\n[root@storage-unixmen ~]#\r\nlets  use  /dev/sdb  like  iscsi  target\r\nmake file  system Ext4  on this  device\r\n[root@storage-unixmen ~]# mkfs.ext4   /dev/sdb\r\nmke2fs 1.42.9 (28-Dec-2013)\r\n/dev/sdb is entire device, not just one partition!\r\nProceed anyway? (y,n) y\r\nFilesystem label=\r\nOS type: Linux\r\nBlock size=4096 (log=2)\r\nFragment size=4096 (log=2)\r\nStride=0 blocks, Stripe width=0 blocks\r\n327680 inodes, 1310720 blocks\r\n65536 blocks (5.00%) reserved for the super user\r\nFirst data block=0\r\nMaximum filesystem blocks=1342177280\r\n40 block groups\r\n32768 blocks per group, 32768 fragments per group\r\n8192 inodes per group\r\nSuperblock backups stored on blocks:\r\n32768, 98304, 163840, 229376, 294912, 819200, 884736Allocating group tables: done\r\nWriting inode tables: done\r\nCreating journal (32768 blocks): done\r\nWriting superblocks and filesystem accounting information: done[root@storage-unixmen ~]#\r\nyou can   also  use  fdisk  /dev/sdb to  created separated   partitions\r\nCreate  /storage  directory and  mount  the  sdb device  to this  partition\r\nmkdir   /storage \r\nmount  -t ext4  /deb/sdb  /storage \r\nLets  check  the   directory  mounted\r\n\r\nroot@storage-unixmen ~]# df  -h \r\nFilesystem               Size  Used Avail Use% Mounted on\r\n/dev/mapper/centos-root   28G  1.1G   27G   4% /\r\ndevtmpfs                 479M     0  479M   0% /dev\r\ntmpfs                    489M     0  489M   0% /dev/shm\r\ntmpfs                    489M  6.8M  483M   2% /run\r\ntmpfs                    489M     0  489M   0% /sys/fs/cgroup\r\n/dev/sda1                497M  168M  330M  34% /boot\r\ntmpfs                     98M     0   98M   0% /run/user/0\r\n/dev/sdb                 4.8G   20M  4.6G   1% /storage\r\n[root@storage-unixmen ~]#\r\n to  make this  mount  permanant    .  please  add  to   /etc/fstab\r\n/dev/sdb  /storage  ext4 defaults  0 0\r\nI- Lets  start  Iscsi admin tool\r\n\r\n[root@storage-unixmen ~]# yum -y install targetcli\r\nII- Access   Admin console\r\n\r\n[root@storage-unixmen ~]# targetcli \r\nWarning: Could not load preferences file /root/.targetcli/prefs.bin.\r\ntargetcli shell version 2.1.fb41\r\nCopyright 2011-2013 by Datera, Inc and others.\r\nFor help on commands, type ''help''.\r\n/> \r\nand go  to this directory \r\ncd backstores/fileio\r\n> cd  /backstores/fileio \r\nIII- create a disk-image with the name “disk01” on /storage/disk01.img with 3G\r\n\r\n/>/backstores/fileio> create disk01 /storage/disk01.img 3G \r\nCreated fileio disk01 with size 3221225472\r\n/backstores/fileio>\r\nIV-create  Target  iqn.2016-02.unixmen.com:storage.target00\r\n\r\n/backstores/fileio> cd   /iscsi \r\n/iscsi> ls\r\no- iscsi .............................................................................................................. [Targets: 0]\r\n/iscsi> create iqn.2016-02.unixmen.com:storage.target00\r\nCreated target iqn.2016-02.unixmen.com:storage.target00.\r\nCreated TPG 1.\r\nGlobal pref auto_add_default_portal=true\r\nCreated default portal listening on all IPs (0.0.0.0), port 3260.\r\n/iscsi>\r\nV- Set  ip   adres   of the target under  Portals folder\r\n\r\n/iscsi> cd  iqn.2016-02.unixmen.com:storage.target00/tpg1/portals/\r\n/iscsi/iqn.20.../tpg1/portals>\r\niscsi/iqn.20.../tpg1/portals> delete 0.0.0.0 3260\r\nDeleted network portal 0.0.0.0:3260\r\n/iscsi/iqn.20.../tpg1/portals> create 192.168.183.129\r\nUsing default IP port 3260\r\nCreated network portal 192.168.183.129:3260.\r\n/iscsi/iqn.20.../tpg1/portals> ls\r\no- portals .................................................................................... [Portals: 1]\r\n  o- 192.168.183.129:3260.................................................................................. [OK]\r\n/iscsi/iqn.20.../tpg1/portals>\r\nVI- Set  LUN\r\n\r\n/iscsi/iqn.20…/tpg1/portals> cd   ../luns\r\n/iscsi/iqn.20…t00/tpg1/luns> create /backstores/fileio/disk01\r\nCreated LUN 0.\r\n/iscsi/iqn.20…t00/tpg1/luns>\r\n\r\nVII  authorize  access .\r\n\r\nin this  method  , we will  open access  for every machine and  without  identification\r\n\r\n \r\n\r\nset attribute authentication=0\r\nset attribute generate_node_acls=1\r\nset attribute demo_mode_write_protect=0\r\nexit\r\n/iscsi/iqn.20...t00/tpg1/luns> cd  ../\r\n/iscsi/iqn.20...target00/tpg1> set attribute authentication=0\r\nParameter authentication is now ''0''.\r\n/iscsi/iqn.20...target00/tpg1> set attribute generate_node_acls=1\r\nParameter generate_node_acls is now ''1''.\r\n/iscsi/iqn.20...target00/tpg1> set attribute demo_mode_write_protect=0\r\nParameter demo_mode_write_protect is now ''0''.\r\n/iscsi/iqn.20...target00/tpg1> exit \r\nGlobal pref auto_save_on_exit=true\r\nLast 10 configs saved in /etc/target/backup.\r\nConfiguration saved to /etc/target/saveconfig.json\r\n[root@storage-unixmen ~]# \r\nVIII- the machine is ready\r\n\r\n[root@storage-unixmen ~]# netstat   -an  |  grep -i    3260 \r\ntcp        0      0 192.168.183.129:3260    0.0.0.0:*               LISTEN     \r\n[root@storage-unixmen ~]# \r\n[root@storage-unixmen ~]# lsblk \r\nNAME            MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT\r\nsda               8:0    0   30G  0 disk \r\n??sda1            8:1    0  500M  0 part /boot\r\n??sda2            8:2    0 29.5G  0 part \r\n  ??centos-root 253:0    0 27.5G  0 lvm  /\r\n  ??centos-swap 253:1    0    2G  0 lvm  [SWAP]\r\nsdb               8:16   0    5G  0 disk /storage\r\nsr0              11:0    1    4G  0 rom  \r\n[root@storage-unixmen ~]# \r\nScreenshot_20160214_232944\r\nIX- Connect  from the Clietnt\r\n\r\nServer is also centos7  with IP 192.168.183.21\r\n\r\n\r\n \r\nfirst    iscsi initiator\r\n\r\nyum install iscsi-initiator-utils.x86_64\r\nMy actual Disks\r\n\r\n[root@node1 ~]# df  -h \r\nFilesystem               Size  Used Avail Use% Mounted on\r\n/dev/mapper/centos-root   28G  1.1G   27G   4% /\r\ndevtmpfs                 479M     0  479M   0% /dev\r\ntmpfs                    489M     0  489M   0% /dev/shm\r\ntmpfs                    489M  6.7M  483M   2% /run\r\ntmpfs                    489M     0  489M   0% /sys/fs/cgroup\r\n/dev/sda1                497M  168M  330M  34% /boot\r\n/dev/sdb                 5.0G   33M  5.0G   1% /glusterfs/storage1\r\ntmpfs                     98M     0   98M   0% /run/user/0\r\nConnect  the ISCSCI   target\r\n\r\nDiscover  the  target\r\n\r\n[root@node1 ~]# iscsiadm   --mode discoverydb --type sendtargets --portal  192.168.183.129   --discover \r\n192.168.183.129:3260,1 iqn.2016-02.unixmen.com:storage.target00\r\nAdd the  disk\r\n\r\n \r\n[root@node1 ~]# iscsiadm   --mode node --targetname  iqn.2016-02.unixmen.com:storage.target00 --portal  192.168.183.129:3260   --login\r\nLogging in to [iface: default, target: iqn.2016-02.unixmen.com:storage.target00, portal: 192.168.183.129,3260] (multiple)\r\nLogin to [iface: default, target: iqn.2016-02.unixmen.com:storage.target00, portal: 192.168.183.129,3260] successful.\r\nCongratulation  you have now  an  extra  disk\r\n\r\n[root@node1 ~]# fdisk  -l \r\nDisk /dev/sdb: 5368 MB, 5368709120 bytes, 10485760 sectors\r\nUnits = sectors of 1 * 512 = 512 bytes\r\nSector size (logical/physical): 512 bytes / 512 bytes\r\nI/O size (minimum/optimal): 512 bytes / 512 bytes\r\nDisk /dev/sda: 32.2 GB, 32212254720 bytes, 62914560 sectors\r\nUnits = sectors of 1 * 512 = 512 bytes\r\nSector size (logical/physical): 512 bytes / 512 bytes\r\nI/O size (minimum/optimal): 512 bytes / 512 bytes\r\nDisk label type: dos\r\nDisk identifier: 0x00047725\r\n   Device Boot      Start         End      Blocks   Id  System\r\n/dev/sda1   *        2048     1026047      512000   83  Linux\r\n/dev/sda2         1026048    62914559    30944256   8e  Linux LVM\r\nDisk /dev/mapper/centos-root: 29.5 GB, 29490151424 bytes, 57597952 sectors\r\nUnits = sectors of 1 * 512 = 512 bytes\r\nSector size (logical/physical): 512 bytes / 512 bytes\r\nI/O size (minimum/optimal): 512 bytes / 512 bytes\r\nDisk /dev/mapper/centos-swap: 2147 MB, 2147483648 bytes, 4194304 sectors\r\nUnits = sectors of 1 * 512 = 512 bytes\r\nSector size (logical/physical): 512 bytes / 512 bytes\r\nI/O size (minimum/optimal): 512 bytes / 512 bytes\r\nDisk /dev/sdc: 3221 MB, 3221225472 bytes, 6291456 sectors\r\nUnits = sectors of 1 * 512 = 512 bytes\r\nSector size (logical/physical): 512 bytes / 512 bytes\r\nI/O size (minimum/optimal): 512 bytes / 8388608 bytes\r\n[root@node1 ~]# lsblk \r\nNAME            MAJ:MIN RM  SIZE RO TYPE MOUNTPOINT\r\nsda               8:0    0   30G  0 disk \r\n??sda1            8:1    0  500M  0 part /boot\r\n??sda2            8:2    0 29.5G  0 part \r\n  ??centos-root 253:0    0 27.5G  0 lvm  /\r\n  ??centos-swap 253:1    0    2G  0 lvm  [SWAP]\r\nsdb               8:16   0    5G  0 disk /glusterfs/storage1\r\nsdc               8:32   0    3G  0 disk \r\nsr0              11:0    1    4G  0 rom  \r\n[root@node1 ~]#\r\nNow   you  can fdisk    /dev/sdc   to   make  partitions \r\n\r\n[root@node1 ~]# fdisk    /dev/sdc \r\nWelcome to fdisk (util-linux 2.23.2).\r\nChanges will remain in memory only, until you decide to write them.\r\nBe careful before using the write command.\r\nDevice does not contain a recognized partition table\r\nBuilding a new DOS disklabel with disk identifier 0xcc2a4d65.\r\nCommand (m for help): n\r\nPartition type:\r\n   p   primary (0 primary, 0 extended, 4 free)\r\n   e   extended\r\nSelect (default p): \r\nUsing default response p\r\nPartition number (1-4, default 1): \r\nFirst sector (16384-6291455, default 16384): \r\nUsing default value 16384\r\nLast sector, +sectors or +size{K,M,G} (16384-6291455, default 6291455): \r\nUsing default value 6291455\r\nPartition 1 of type Linux and of size 3 GiB is set\r\nCommand (m for help): t\r\nSelected partition 1\r\nHex code (type L to list all codes): 83\r\nChanged type of partition ''Linux'' to ''Linux''\r\nCommand (m for help): p\r\nDisk /dev/sdc: 3221 MB, 3221225472 bytes, 6291456 sectors\r\nUnits = sectors of 1 * 512 = 512 bytes\r\nSector size (logical/physical): 512 bytes / 512 bytes\r\nI/O size (minimum/optimal): 512 bytes / 8388608 bytes\r\nDisk label type: dos\r\nDisk identifier: 0xcc2a4d65\r\n   Device Boot      Start         End      Blocks   Id  System\r\n/dev/sdc1           16384     6291455     3137536   83  Linux\r\nCommand (m for help): w\r\nThe partition table has been altered!\r\nCalling ioctl() to re-read partition table.\r\nSyncing disks.\r\n[root@node1 ~]#\r\ncreate a  folder  /iscsi-disk\r\n\r\nroot@node1 ~]# mkdir /iscsi-disk \r\nFormat  the disk  /dev/sdc1  with ext4\r\n\r\n[root@node1 ~]# mkfs.ext4   /dev/sdc1 \r\nmke2fs 1.42.9 (28-Dec-2013)\r\nFilesystem label=\r\nOS type: Linux\r\nBlock size=4096 (log=2)\r\nFragment size=4096 (log=2)\r\nStride=0 blocks, Stripe width=2048 blocks\r\n196224 inodes, 784384 blocks\r\n39219 blocks (5.00%) reserved for the super user\r\nFirst data block=0\r\nMaximum filesystem blocks=803209216\r\n24 block groups\r\n32768 blocks per group, 32768 fragments per group\r\n8176 inodes per group\r\nSuperblock backups stored on blocks: \r\n        32768, 98304, 163840, 229376, 294912\r\nAllocating group tables: done                            \r\nWriting inode tables: done                            \r\nCreating journal (16384 blocks): done\r\nWriting superblocks and filesystem accounting information: done \r\n[root@node1 ~]#\r\n \r\n\r\nMount  the  dormated  partion  to  /iscsi-disk\r\n\r\n[root@node1 ~]# mount /dev/sdc1  /iscsi-disk/\r\n[root@node1 ~]# df -h \r\nFilesystem               Size  Used Avail Use% Mounted on\r\n/dev/mapper/centos-root   28G  1.1G   27G   4% /\r\ndevtmpfs                 479M     0  479M   0% /dev\r\ntmpfs                    489M     0  489M   0% /dev/shm\r\ntmpfs                    489M  6.8M  483M   2% /run\r\ntmpfs                    489M     0  489M   0% /sys/fs/cgroup\r\n/dev/sda1                497M  168M  330M  34% /boot\r\n/dev/sdb                 5.0G   33M  5.0G   1% /glusterfs/storage1\r\ntmpfs                     98M     0   98M   0% /run/user/0\r\n/dev/sdc1                2.9G  9.0M  2.8G   1% /iscsi-disk\r\n[root@node1 ~]#\r\nScreenshot_20160214_232807\r\nTo make    mount htis  disk  permanntly   every   reboot  please   add this to  your  /etc/fstab file\r\n\r\n \r\n\r\n/dev/sdc1  /iscsi-disk/   ext4    defaults,_netdev   0 0\r\nsave and exit\r\n\r\n \r\n\r\nDone', '2016-02-15 00:00:00', 1, 'An iSCSI target can be a dedicated physical device in a network, or it can be an iSCSI software-configured logical device on a networked storage server. The target is the end point in SCSI bus communication. Storage on the target, accessed by an initiator, is defined by LUNs. (Redhat)', 'How to create an iSCSI Target in Centos7', 1, 1),
(2, 'A token that performs a control function. It is a newline or one of the following:\r\n\r\nAmpersand ( & ) \r\n\r\nWhen a line ends with ampersand &, the shell will not wait for the command to finish. You will get your shell prompt back, and the command is executed in background.\r\n\r\nfor example :\r\n\r\nAmpersand\r\n\r\nSemicolon (;)\r\n\r\nYou can put two or more commands on the same line separated by a Semicolon ; . Both series will be executed sequentially with the shell waiting for each command to finish before starting the next.\r\n\r\nFor example :\r\n\r\nsemi\r\n\r\nDouble Ampersand (&&)\r\n\r\nWhen using && the second command is executed only if the first one succeeds.\r\n\r\nFor example:\r\n\r\ndouble_ampersand\r\n\r\nDouble vertical bar (||)\r\n\r\nThe || represents a logical OR. The second command is executed only when the first command is fail.\r\n\r\nFor example :\r\n\r\ndouble_vertical\r\n\r\nCombine && with ||\r\n\r\nYou can use this logical AND and logical OR to write an if-then-else structure on the command line.\r\n\r\nFor example:\r\n\r\ncombine\r\n\r\nPound sign (#)\r\n\r\nEverything written after a pound sign (#) is ignored by the shell. This is useful to write a shell comment, but has no influence on the command execution or shell expansion.\r\n\r\nFor example:\r\n\r\npound\r\n\r\nEscaping special characters\r\n\r\nThe backslash character enables the use of control characters, but without the shell interpreting it, this is called escaping characters.\r\n\r\nFor example:\r\n\r\nbackslash\r\n\r\nEnd of line backslash\r\n\r\nLines ending in a backslash are continued on the next line. The shell does not interpret the newline character and will wait on shell expansion and execution of the command line until a newline without backslash is encountered.\r\n\r\nFor example :\r\n\r\necho\r\n\r\nDollar Question mark ($?)\r\n\r\nThe exit code of the previous command is stored in the shell variable $?. Actually $? is a shell parameter and not a variable. This parameter is used to check the last executed command status. If the value returned by $? is 0, that was a success one otherwise that was a failed one.\r\n\r\ndollar\r\n\r\n0 – Represents a successful command.\r\n1 or any-other non zero – Represents a failed output.\r\n\r\nYou can use the above operators in your server administration’s works or script that running on client :-)\r\n\r\nmake me happy with your comments if you have any questions :-)', '2016-02-08 00:00:00', 0, NULL, 'How Can We Use Operators In Linux and Unix CLI?', 2, 3),
(5, 'Now lets see how we can solve kernel panic, my dear friend Arcush wrote an amazing article about kernel panic which it’s name is “Kernel panic, 11min” that I translated it in English for you, by the assumption that you didn’t delete files in pacman cache we continue this tutorial.\n\nBy supposition that kernel has problem syncing some packages/libraries because they are broken or etc we “chroot” and we install those packages again.\n\n This means system is working correctly now and it will come up after about 1min and 30 seconds !!\nI wish this article was useful for you :)', '2016-02-05 00:00:00', 1, 'If you are Arch Linux user you may experienced kernel panic ! in operating systems which are based on Unix, kernel panic problem is not end of everything (however there is another type of breaking which is dead of OS !!)  . Kernel panic happens because of some hardware actions such as a lot CPU working when RAM is not enough or pluging and unpluging the hardwares a lot and etc. Software reasons that kernel panic happens are giving administrator access to  many users or installing and removing packages and files more than normal. In fact with software actions you make hardware problem and kernel panic happens for example you install graphic card driver in wrong way then you will find graphic problem and kernel can’t take it and get confused so kernel panic happens. These reasons were common reasons that kernel panic happens although it has other reasons !', 'Solve Kernel Panic on Arch Linux', 3, 2),
(6, 'WHAT IS A FORK BOMB?\r\n\r\nFork_bomb\r\n\r\nThe name sounds Fork bomb does not throw dining forks at you, when you executing the strings in terminal. In terms of nixology (Linux & Unix) the word fork means, to create a new process.Similarly, when you create a new process using ‘fork’ (actually a function that can be called on Linux/Unix-like machines), the new process is created from the image of the original one and is basically a inherited copy of the parent process.\r\nA fork bomb will calls the fork function indefinitely and rapidly in no time, thus exhausting all system resources. It comes in the category of Denial of Service attack due to its nature of quickly ripping up system resources and making it unusable within a very short span of time.\r\n\r\nAll these special characters stands with their unique functionality in *nix operating system. Fork bomb actually associated with the concept of recursion in bash script by using functions in it.\r\n\r\nSyntax of function in bash,\r\n\r\nfunction_name()\r\n\r\n{\r\nCommands\r\n}\r\n\r\nHOW FORK BOMB WORKS?\r\n\r\nIn this case ‘:’ colon is the function name then followed by ‘()’ parentheses and curly brace ‘{‘ to open a function, then the definition of ‘:|:&’ tells the bash  to launch the ‘:’ function and ‘|’ pipe its output to the same function ‘:’ and send the process to the background defined by ‘&’, so that it can’t be killed by hitting “Ctrl + C”. Then the close curly brace ‘}’ followed by ‘:;’ which points the function again to keep the process recursive.\r\n\r\nTo launch the bomb, all you need to do is just to copy or type   :(){ :|:& };:   this code in Terminal and hit Enter. Your session will get slow down to hell in matter of seconds and you will be left with no option but to go with warm reset. The actual time in which your system will succumb to paralysis depends on the speed of your processor, number of processing cores available and the amount of RAM installed. Even though the size of swap partition is also a factor, if it starts getting used by the bomb, the system would typically take long enough to respond for you.\r\n\r\nBefore we proceed further let me make sure that Fork bomb is not a property of Linux, the technique of creating new processes does work on Windows as well and also the same problem can be raised in other system programming languages such as C or C++, for your instance  compile the following code and execute it, you will come to know that.\r\n\r\n\r\nFORK BOMB IN C\r\n#include\r\nint main(void) {\r\n    for(;;)\r\n    fork();\r\n    return 0;\r\n}\r\n\r\nHOW TO PROTECT FROM FORK BOMB?\r\n\r\nFork bombs hang the system by creating a ‘N’ number of processes. The worst part is that one does not even need to be the super user to launch a fork bomb. To shield your system from Fork bomb ensure that you are limiting the number of processes to the local users where they could create, you can limit around 1000 to 4000 process for the local users to create. Generally a user could work about 200-300 process at same time. However for people who do a lot of multitasking, 1000 might be little less.\r\n\r\nUnderstanding /etc/security/limits.conf file!\r\n\r\nEach line describes a limit for a user in the form:\r\n<domain> <type> <item> <value>\r\nWhere:\r\n\r\n<domain> can be:\r\nan user name\r\na group name, with @group syntax\r\nthe wildcard *, for default entry\r\nthe wildcard %, can be also used with %group syntax, for maxlogin limit\r\n<type> can have the two values:\r\n“soft” for enforcing the soft limits\r\n“hard” for enforcing hard limits\r\n<item> can be one of the following:\r\ncore – limits the core file size (KB)\r\n<value> can be one of the following:\r\ncore – limits the core file size (KB)\r\ndata – max data size (KB)\r\nfsize – maximum filesize (KB)\r\nmemlock – max locked-in-memory address space (KB)\r\nnofile – max number of open files\r\nrss – max resident set size (KB)\r\nstack – max stack size (KB)\r\ncpu – max CPU time (MIN)\r\nnproc – max number of processes\r\nas – address space limit\r\nmaxlogins – max number of logins for this user\r\nmaxsyslogins – max number of logins on the system\r\npriority – the priority to run user process with\r\nlocks – max number of file locks the user can hold\r\nsigpending – max number of pending signals\r\nmsgqueue – max memory used by POSIX message queues (bytes)\r\nnice – max nice priority allowed to raise to\r\nrtprio – max realtime priority\r\nchroot – change root to directory (Debian-specific)\r\nTo limit the number of processes according to the users, you can open the file /etc/security/limits.conf and add the following line at the bottom:\r\n\r\n\r\n \r\n\r\nmohammad hard nproc 4000\r\n\r\nThis will keep the the specified user account to restrict more than 4000 processes. Save the file and reboot the system and try with launching the Fork bomb. System should prevent the crash and withstand the attack now!\r\n\r\nIf a Fork bomb has already been launched and the restrictions for number of processes are active, you can login as root and kill all the bash processes to terminate the fork bomb. In case if a Fork bomb script is activated by a local user and you haven’t restrict the number of processes to that particular user, but still your CPU left with little time to clear the Fork bomb.\r\n\r\nYou should not use the following command to kill the script.\r\n\r\n$killall -9 Script_Name\r\n\r\nThis will not work due the nature of a fork bomb. The reason is the killall does not hold a lock on the process table so each one that is killed a new one takes its place in the process table. Also you will not be able to run a killall due to the shell forking off another shell to run the killall.\r\n\r\nInstead you can run these command to stop Fork bomb,\r\n\r\n$ exec killall -9 ScritName\r\n\r\n$ exec killall STOP ScriptName\r\n\r\nNOTE :\r\n\r\nThis Restrictions will have no effect on the root user or any process with the CAP_SYS_ADMIN or CAP_SYS_RESOURCE capabilities are not affected by this kind of limitation on a Linux based system.\r\n\r\nHope you enjoyed the article , make me happy with your comments if you have any questions :-)', '2016-01-19 00:00:00', 1, 'If you are not thrilled with the real bomb, you can try typing this  :(){ :|:& };:  on your Linux terminal to crash your computer. you do not need to be the root user to do that. That string is known as the Fork bomb. Before you get to know how that works, it would be better to know what a fork bomb does exactly.', 'What Is Fork Bomb And How Can You Prevent This Danger?', 2, 3),
(7, 'OK, first things first – you should go to www.worldofspectrum.org , and search out Exolon in the “Infoseek” search engine that they have there, and play it. Why? Well, as it turns out, it’s author, Raffaele Cecco took somewhat of a similar journey to mine in his programming life – he graduated from the world of Z80 assembly language on the Spectrum to Javascript (though I have seen his name on the credits of a DOS game from sometime in the middle, one in fact, that I downloaded from www.abandonia.com much later), and has written an excellent book on the subject called “Supercharged Javascript Graphics”. I highly recommend you check this book out. In it, amongst other things, he develops a complete Space Invaders-ish game, replete with the entire source – an excellent educational adventure for you, the reader. Now, if you have played retro games on emulators, you may not have let matters rest there of course, and even besides that – you may also be familiar with the commercial console and PC games of today. And you might just have the urge to make the kind of things that you see your friends playing, and see in game parlours and so on, by using, say for example, things like PlayCanvas. Now, I myself have never tried PlayCanvas, but in true hacker spirit, I would like to warn you against this. There is nothing wrong with starting simple, and working your way up, so that you know every inch of what your program is doing, start to finish. However, the first Doom, for example, was released in 1993, so if you have to start from there and rise up through to the ranks of the game programming elite of today, well, I guess, life is not that long. However, using some type of readymade “game maker” program which spits out code for you is really, meant for small children, not YOU, the eleet hacker! This is something I’ve devoted some thought to, and well, really, there’s no easy answer to this – you’ll need to strike a balance between being a True Hacker, and…….. well, wowing the young audience of today, and commercial success. To make things easier for you, there is the the fact that mobile games exist, which, depending on hardware model can be fairly simplistic, at times not much more sophisticated than a Spectrum game. To start off this exciting journey of yours, let me recommend this next book, which is one of my most favourite programming books of all time – Michael Abrash’s Graphics Programming Blackbook. Michael worked with John Carmack on Quake, then worked at Valve, and today is at Facebook working on Oculus Rift – type stuff, and in fact was kind enough to reply to an email I sent him after tracking him down on the web some time back, matter of fact, we had a little chat. In the book (which has a foreward written by Mr. Carmack himself), Michael details graphics development starting from pixels to lines to polygons right through to the techniques used by the Quake engine, and makes a sometimes heavy subject easy by peppering the text with anecdotes taken from his own life (you’ll love the story about Bert!). It’s a DOS era book, and a lot of the material is obsolete by now (how to abuse your VGA card is dealt with in excruciating detail), and is simply inapplicable to you since Linux, as a protected mode OS, will restrict you from doing a lot of the the things mentioned there. However, if you’re insane, and want to get hold of an old 486 or P-I from somewhere, and install DOS and some programming tools to try out some of the stuff talked about, well, I guess you’ll be the one writing this column next! Just to point out, you’ll need about a Class 11 level maths background, if you’re younger than that, well, Khan Academy’s your friend! Don’t let me stop you! To make matters unbelievably wonderful, the entire book is available for FREE! Not as a pirated edition, but because Michael actually believes in sharing his knowlege, for the good of the community. Sounds amazing, right? Go here: http://www.phatcode.net/res/224/files/html/index.html .\r\n\r\nNow, at this point, I have a humble confession to make. I don’t know C! Specifically pointers. I never got into it at a young age, because after life with my Sinclair ZX Spectrum had come to a halt, I didn’t have access to a PC with a C compiler so that I could follow things in a natural progression (and my parents wanted me to get off the computer and focus on my schoolwork – probably the main reason I did so badly there!). I do remember reading about them at the time (in a book I got for my birthday at the time, in fact), but since I couldn’t actually try it out anywhere, they never became part of my bloodstream! This is the main reason I couldn’t actually try out anything from the Abrash book, since the whole thing assumes you’re adept at C! This has been a huge stumbling block in my programming education, since every single book on data structures or graphics programming, or what have you (not to mention websites like this one), assumes you know C. Now, today, where it’s actually taught in school (wasn’t the case back then), let me give you my opinion – I’m glad I never learnt pointers! There’s nothing wrong with understanding indirection, but when you’re trying to think of and implement a particular algorithm, trying to think of what the 0s and 1s are doing inside the computer is just hugely counter intuitive. This is not how human beings think. C was made so that an operating system could be written in it – that is the crux of how pointers came into being, and for some reason that hacker language caught on to become the most prevalent language in the whole world! Of course, it also led a young kid called Linus Torvalds to use it to do it all over again starting in 1991 (incidentally Linus, before the PC, worked on the QL, another member of the Sinclair family, a sort of a “big cousin” to the Spectrum), thanks to which you’re reading this website today, so I guess it wasn’t altogether a bad thing. But I, for one am glad that we’ve moved on to things like Javascript, in today’s day and age, and it makes me happy that we don’t have to worry about what’s zapping in and out of RAM when trying to write a game. Just at that point where those in charge of the Indian education system want their charges to know about nothing else but the syntax of weird things with asterisks in them (it seems, the more asterisks, the better), as if that was important. Trust the fools! Incidentally, I did get hold of a Youtube video about pointers sometime back, and followed it through, and yes, I did finally get what they are (where was that animation back in 1992?), but I guess it’s too late now – Javascript occupies much more of my mind now than C ever will, and I can’t say that makes me unhappy in any way. All along, I knew what [ and ] do in Assembly in any case! I just wish there were more folks like me, who will now have the happy task of porting, in their own minds, all the code in the Abrash book, to whatever their favourite language is, so that in the case of Javascript, wonder of wonders – their browser can show them the joy of a rotating cube! That’s why the exhortations of this article. By the way, I suggest you Youtube for “banana bread” some time – good stuff! This is clearly the future, and you need to get a handle on it.\r\n\r\nOK, so….. one more thing needs clearing up before I leave though – now there’s Wayland which you may and have heard of, and which changes things considerably, although it’s next to impossible to find out exactly what it is, and what its innards consist of (for those who don’t know, it’s a new display server technology – and by the way, the latest version of the Enlightenment Window Manger now works with it!). Of course, if you’re a browser programmer, this doesn’t matter to you anyway, beyond what you can’t help – if your Javascript browser games run slower on Wayland than on X, well, there’s no way to fix that, unless you know C and are prepared to dig deep into it’s code – let me point you in a direction far, far away from that, pun intended! Let’s spend the rest of our time discussing actual game ideas – God knows I’ve had a couple myself, I’d love to hear yours – send them to the editor, and maybe we can come to some sort of consensus amongst our readers about who would like to take a shot at implementing their favourite ones…..? Cheers, guys!', '2016-01-24 00:00:00', 1, NULL, 'Sexy MF says things related to game programming on Linux, and tells you why you shouldn’t learn C!', 1, 3),
(8, 'Prerequisites\r\n\r\nwe will be using Ubuntu 15.10 as 1 master node, 2 Slave/data nodes. hostname for namenode  will be masternode, datanodes  will have hostname slave1 and  slave2 respectively.\r\n\r\nmasternode IP address:192.51.10.10\r\n\r\nSlave1 IP Address:192.51.10.11\r\n\r\nSlave2 IP Address:192.51.10.12\r\n\r\nConfiguration\r\n\r\nInstillation process is similar to previous tutorial except few changes. First of all let us configure master node .\r\n\r\nDefine hostname of Namenode\r\n\r\n# vim /etc/hostname\r\nSelection_011\r\n\r\n \r\n\r\nDefine hosts in /etc/hosts file\r\n\r\n# vim /etc/hosts\r\nSample output\r\n\r\n127.0.0.1       localhost\r\n192.51.10.10    masternode\r\n192.51.10.11    slave1\r\n192.51.10.12    slave2\r\nConfigure Hadoop Services\r\n\r\n# cd /usr/local/hadoop/etc/hadoop/\r\nEdit hdfs-site.xml\r\n\r\n# vim /usr/local/hadoop/etc/hadoop/hdfs-site.xml\r\nFile will look like below, change replication value to 3.\r\n\r\n<configuration>\r\n<property>\r\n <name>dfs.replication</name>\r\n <value>3</value>\r\n</property>\r\n<property>\r\n  <name>dfs.namenode.name.dir</name>\r\n  <value>file:///usr/local/hadoop/hadoopdata/hdfs/namenode</value>\r\n</property>\r\n</configuration>\r\nMake sure that you possess a namenode directory under /usr/local/hadoop\r\n\r\n# mkdir -p /usr/local/hadoop/hadoopdata/hdfs/namenode\r\n# sudo chown -R hadoop:hadoop /usr/local/hadoop/\r\nSimilarly edit yarn-site.xml, it  will look like below, make sure you have assigned hostname of masternode appropriately\r\n\r\n# vim yarn-site.xml\r\nSample output\r\n\r\n<configuration>\r\n<property>\r\n <name>yarn.nodemanager.aux-services</name>\r\n <value>mapreduce_shuffle</value>\r\n</property>\r\n<property>\r\n <name>yarn.resourcemanager.scheduler.address</name>\r\n <value>masternode:8030</value>\r\n</property>\r\n<property>\r\n <name>yarn.resourcemanager.address</name>\r\n <value>masternode:8032</value>\r\n</property>\r\n<property>\r\n  <name>yarn.resourcemanager.webapp.address</name>\r\n  <value>masternode:8088</value>\r\n</property>\r\n<property>\r\n  <name>yarn.resourcemanager.resource-tracker.address</name>\r\n  <value>masternode:8031</value>\r\n</property>\r\n<property>\r\n  <name>yarn.resourcemanager.admin.address</name>\r\n  <value>masternode:8033</value>\r\n</property>\r\n</configuration>\r\nMake sure core-site.xml have appropriate hostname\r\n\r\nSelection_012\r\n\r\n \r\n\r\nCreate a file named slaves under /usr/local/hadoop/etc/hadoop directory  and assign hostnames of datanodes\r\n\r\n# vim /usr/local/hadoop/etc/hadoop/slaves\r\nPut following entries\r\n\r\nslave1\r\nslave2\r\nSimilarly create file named mastersunder same directory hierarchy\r\n\r\n# vim /usr/local/hadoop/etc/hadoop/masters\r\nEnter following\r\n\r\nmasternode\r\nWe have a working master node at this stage, let us create 2 slave nodes. We created two  clone virtual machines using VirtualBox, first clone is slave1 and second cone is slave2, as this machine is clone of Masternode so we will be having all of the hadoop configuration files (.xml) in ready to use form.\r\n\r\nSelection_003\r\n\r\nSimilarity create another clone for slave2 datanode.\r\n\r\nChange IP address to 192.51.10.11\r\n\r\nSelection_013\r\n\r\nChange hostname to slave1 and reboot the system. Replete the process for another VirtualBox Clone which will be used as slave2,assign IP address 192.51.10.12 to slave2.\r\n\r\nName we have one NameNode (masternode) with IP address 192.51.10.10 and two datanodes (slave1, slave2).\r\n\r\nSelection_010\r\n\r\nNow switch back to master node and share ssh rsa keys with slave1 and slave2, so that there is no need for ssh passwords.\r\n\r\n# ssh-keygen -t rsa\r\n# ssh hadoop@192.51.10.11 "chmod 755 .ssh; chmod 640 .ssh/authorized_keys"\r\n# cat .ssh/id_rsa.pub | ssh hadoop@192.51.10.12 ''cat >> .ssh/authorized_keys''\r\n# ssh hadoop@192.51.10.12 "chmod 755 .ssh; chmod 640 .ssh/authorized_keys"\r\nReboot all three systems to make sure all things are going smooth.\r\n\r\nEdit hdfs-site.xml file of slave1 and slave2 data nodes make sure you have following entries\r\n\r\n<configuration>\r\n<configuration>\r\n<property>\r\n  <name>dfs.data.dir</name>\r\n   <value>file:///usr/local/hadoop/hadoopdata/hdfs/datanode</value>\r\n</property>\r\n</configuration>\r\nCreate  /usr/local/hadoop/hadoopdata/hdfs/datanode directory  on both data nodes\r\n\r\n# mkdir -p /usr/local/hadoop/hadoopdata/hdfs/datanode\r\n# chown -R hadoop:hadoop /usr/local/hadoop/\r\nGo to Masternode and run start node services\r\n\r\n# cd /usr/local/hadoop/sbin && ls\r\nSelection_014\r\n\r\nRun all node services\r\n\r\n# ./start-all.sh\r\nSelection_015\r\n\r\nWe can see that both of datanodes (slave1, slave2) are working properly.\r\n\r\n\r\n \r\nRun jps command on  Masternode\r\n\r\n# jps\r\nSample output\r\n\r\n8499 SecondaryNameNode\r\n8922 Jps\r\n8650 ResourceManager\r\nSwith to Slave1 and run jps command again\r\n\r\n# ssh hadoop@slave1\r\n\r\n# jps\r\n\r\nSample output, datanode is working\r\n\r\n4373 DataNode\r\n4499 NodeManager\r\n4671 Jps\r\nSimilarly in slave2 datanode is working perfectly\r\n\r\nSelection_016\r\n\r\nMultinode  Hadoop Cluster installation process is over at that  stage.\r\n\r\nOpen browser and type\r\n\r\nhttp://192.51.10.10:8088/cluster/nodes <change IP addr in your scenario>\r\n\r\nTaht Selection_017\r\n\r\nThats it! Have Fun!!', '2016-02-09 00:00:00', 0, 'Preface\r\n\r\nWe give a brief introduction of Hadoop in previous tutorial, for today we will learn to install Hadoop on multiple nodes, in demonstration scenario  we will be using Ubuntu 15.10 as Desktop, we will create 2 Slave or Data Nodes along with 1 Name node. Make sure you have shared ssh public keys with Data nodes and assign appropriate IP addresses, host name and other Hadoop  services (we will mention in tutorial) required to run Hadoop multiple cluster node.', 'Install Hadoop on multiple nodes using Ubuntu 15.10', 4, 1);
INSERT INTO `Article` (`id`, `content`, `pubDate`, `published`, `subTitle`, `title`, `author_id`, `category_id`) VALUES
(9, 'The topology will be as follows:\r\nSnort-topology\r\n\r\nApache, MySQL and PHP already installed and configured.\r\n\r\nIn /usr/local/etc/php.ini file configure the  following lines:\r\nerror_reporting = E_ALL & ~E_NOTICE\r\ndate.timezone = ''Asia/Baku''\r\ninclude_path = ".:/usr/local/share/pear:/usr/local/share/fpdf"\r\n\r\ncd /usr/ports/security/snort\r\nmake config                         # Choose modules\r\nSnort-port\r\nmake -DBATCH install                # Install\r\n\r\nmkdir /root/snortrules # create folder which we will download the rules\r\ncd /root/snortrules           # Enter the folder\r\n\r\nRegister in site http://snort.org, and then download snortrules-snapshot-2970.tar.gz file to our server folder /root/snortrules:\r\ntar zxf snortrules-snapshot-2970.tar.gz   #  extract the rules\r\n\r\nMove the rules to the necessary address:\r\nmv /root/snortrules/so_rules/ /usr/local/etc/snort/\r\nmv /root/snortrules/rules/ /usr/local/etc/snort/\r\n\r\nWhen configure BARNYARD2  we will need ‘sid-msg.map’ and ‘gen-msg.map’ files.  So we copy that before to the ‘/usr/local/etc/snort’ folder.\r\n\r\ncp /root/snortrules/etc/sid-msg.map /usr/local/etc/snort\r\ncp /usr/ports/security/snort/work/snort-2.9.7.0/etc/gen-msg.map /usr/local/etc/snort\r\n\r\nturn off USBUS interface, because when SNORT will sniff the network it will use first interface usbus0 device and after that will output error. You must reboot after it:\r\necho hw.usb.no_pf=1 >>/boot/loader.conf\r\ntouch /usr/local/etc/snort/rules/blacklist.rules      # Create needed files.\r\ntouch /usr/local/etc/snort/rules/whitelist.rules # Create needed files.\r\n\r\nIf we want to start snort with different user, we must create it before:\r\nadduser\r\nUsername: snort\r\nFull name: Snort IPS User\r\nUid (Leave empty for default): 1003\r\nLogin group [snort]:\r\nLogin group is snort. Invite snort into other groups? []:\r\nLogin class [default]:\r\nShell (sh csh tcsh nologin) [sh]: nologin\r\nHome directory [/home/snort]:\r\nHome directory permissions (Leave empty for default):\r\nUse password-based authentication? [yes]: no\r\nLock out the account after creation? [no]: no\r\nUsername   : snort\r\nPassword   : <disabled>\r\nFull Name  : Snort IPS User\r\nUid        : 1003\r\nClass      :\r\nGroups     : snort\r\nHome       : /home/snort\r\nHome Mode  :\r\nShell      : /usr/sbin/nologin\r\nLocked     : no\r\n\r\nchown –R snort:snort /usr/local/etc/snort       # Change user and group for snort folder.\r\n\r\nstart configuration of /usr/local/etc/snort/snort.conf file:\r\nipvar HOME_NET [10.50.19.0/24,10.50.3.0/24]     # Declare Local Subnets in variable.\r\n\r\nThe same as in the ‘/usr/local/etc/snort/snort.conf’ file for simple rules, so-rules and preproc-rules edit and change the path. Do not forget that all error logs are collected in ‘/var/log/messages’ file.\r\nvar RULE_PATH ./rules\r\nvar SO_RULE_PATH ./so_rules\r\nvar PREPROC_RULE_PATH ./preproc_rules\r\nvar WHITE_LIST_PATH ./rules\r\nvar BLACK_LIST_PATH ./rules\r\n\r\nSet path for Dynamic preprocessor engine and detector:\r\ndynamicpreprocessor directory /usr/local/lib/snort_dynamicpreprocessor\r\ndynamicengine /usr/local/lib/snort_dynamicengine/libsf_engine.so\r\ndynamicdetection directory /usr/local/lib/snort_dynamicrules\r\n\r\nmkdir /usr/local/lib/snort_dynamicrules               # Create needed folder\r\n\r\nNote: If in the folder is not found any file, we must copy needed files with command below:\r\ncp /usr/ports/security/snort/work/snort-2.9.7.0/src/dynamic\r\npreprocessors/build/usr/local/lib/snort_dynamicpreprocessor/* /usr/local/lib/snort_dynamicpreprocessor\r\n\r\nYou can also find dynamic engine file from this path /usr/ports/security/snort/work/snort-2.9.7.0/src/dynamic-plugins/sf_engine/.libs/libsf_engine.so\r\nwhitelist $WHITE_LIST_PATH/whitelist.rules, # change the name of white_list.rules file to whitelist.rules\r\nblacklist $BLACK_LIST_PATH/blacklist.rules      # change the name of black_list.rules to blacklist.rules. Save the  snort.conf file and exit.\r\n\r\nWe also find the line below in the file /usr/local/etc/snort/snort.conf and add comment before the line because, we do not need local rules:\r\n#include $RULE_PATH/local.rules\r\n\r\nAnd at the end before all includes we must set output unified2 as below (You must delete nostamp):\r\noutput unified2: filename snort.log, limit 32, mpls_event_types, vlan_event_types\r\n\r\nThis is needed for autoupdate snort rules.  But you must register in the http://snort.org site to get oinkcode because, it will be needed for update in our url link.\r\ncd /usr/ports/security/oinkmaster         # Enter the port\r\nmake config                               # Choose needed modules\r\noinkmaster-port\r\nmake -DBATCH install                      # Install\r\n\r\necho "check_certificate = off" > /root/.wgetrc        # Turn off certificate checking for WGET\r\n\r\nIn the file /usr/local/bin/oinkmaster find the address that the following lines are in it:\r\n# Make sure all urls look ok, and untaint them.\r\nmy @urls = @{$config{url}};\r\n$#{$config{url}} = -1;\r\nforeach my $url (@urls) {\r\nclean_exit("incorrect URL: \\"$url\\"")\r\n# Delete the line and,\r\nunless ($url =~ /^((?:https*|ftp|file|scp):\\/\\/.+\\.(?:tar\\.gz|tgz))$/ || $url =~ /^(dir:\\/\\/.+)/);       \r\n# Add this line\r\n      unless ($url =~ m,(http.*?://([^\\s)\\"](?!ttp:))+),g); \r\nmy $ok_url = $1;\r\n\r\nPrepare master configuration file for OinkMaster. But you must get generated code for OinkCode, from your registered account(As the print screen):\r\noinkcode-page\r\ncp /usr/local/etc/oinkmaster.conf.sample /usr/local/etc/oinkmaster.conf\r\n\r\nI must say that, the pathes of rules shown in URL starting with the name snortrules-snapshot-2970.tar.gz. You must take the number 2970 from Snort version, in order to match. You can get the version with the following command:\r\nsnort -V\r\n,,_     -*> Snort! <*-\r\no"  )~   Version 2.9.7.0 GRE (Build 149) FreeBSD\r\n''''''''    By Martin Roesch & The Snort Team: http://www.snort.org/contact#team\r\nCopyright (C) 2014 Cisco and/or its affiliates. All rights reserved.\r\nCopyright (C) 1998-2013 Sourcefire, Inc., et al.\r\nUsing libpcap version 1.4.0\r\nUsing PCRE version: 8.35 2014-04-04\r\nUsing ZLIB version: 1.2.8\r\n\r\ncat /usr/local/etc/oinkmaster.conf        # Configuration file will be as follows\r\nurl = http://www.snort.org/rules/snortrules-snapshot-2970.tar.gz?oinkcode=a1d3eb035b7e51f9598398c4bfe18ab89c8be17d\r\npath = /bin:/usr/bin:/usr/local/bin\r\ntmpdir = /home/oinkmaster/tmp/\r\nupdate_files = \\.rules$|\\.config$|\\.conf$|\\.txt$|\\.map$\r\nskipfile local.rules\r\nskipfile deleted.rules\r\nskipfile snort.conf\r\n\r\nmkdir -p /home/oinkmaster/tmp/            # Create temp folder\r\n\r\nWe will need the makesidex.pl file for signature maps and configuration. For that do the following steps:\r\ncp /usr/ports/security/oinkmaster/work/oinkmaster-2.0/contrib/makesidex.pl /usr/local/etc/snort\r\nchmod 700 /usr/local/etc/snort/makesidex.pl           # Set as executable\r\n./makesidex.pl /usr/local/etc/snort/rules/ > /usr/local/etc/autodisable.conf\r\n\r\nIn the end test updates:\r\noinkmaster -o /usr/local/etc/snort/rules -C /usr/local/etc/oinkmaster.conf -C /usr/local/etc/autodisable.conf\r\nLoading /usr/local/etc/oinkmaster.conf\r\nLoading /usr/local/etc/autodisable.conf\r\nDownloading file from http://www.snort.org/rules/snortrules-snapshot-2970.tar.gz?oinkcode=a1d3eb035b7e51f9598398c4bfe18ab89c8be17d... done.\r\nArchive successfully downloaded, unpacking... done.\r\nSetting up rules structures... done.\r\nProcessing downloaded rules... disabled 0, enabled 0, modified 0, total=21885\r\nSetting up rules structures... done.\r\nComparing new files to the old ones... done.\r\n\r\n[***] Results from Oinkmaster started 20141027 23:22:35 [***]\r\n[*] Rules modifications: [*]\r\nNone.\r\n[*] Non-rule line modifications: [*]\r\nNone.\r\n[*] Added files: [*]\r\nNone.\r\n\r\nFor automatization our jobs we must add 5:30 schedule every morning to the /etc/crontab file(restart the cron daemon):\r\n# Snort Rules Update\r\n30      5       *       *       *       root    /usr/local/bin/oinkmaster -o /usr/local/etc/snort/rules/ >/dev/null 2>&1\r\n\r\n/etc/rc.d/cron restart              # Restart the daemon\r\n\r\nWe try to start snort from the Console. But don’t forget to check existing of /var/log/snort folder before. If it is not exist you must create.\r\nsnort -c /usr/local/etc/snort/snort.conf\r\necho ''snort_enable="YES"''>> /etc/rc.conf  # Add snort to startup\r\n\r\n## You can also add lines below to /etc/rc.conf file.\r\n## But in my situation I used just line before.\r\n## Don’t forget, in my situation snort listened on all interfaces\r\n#snort_interface="em0"\r\n#snort_conf="/usr/local/etc/snort/snort.conf"\r\n#snort_group="snort"\r\n#snort_flags="-D -q"\r\n\r\n/usr/local/etc/rc.d/snort start                 # Start the snort\r\n\r\nps -ax | grep snort.conf | grep -v grep  # Check snort PID\r\n1278  -  Ss     0:09.78 /usr/local/bin/snort -D -q -c /usr/local/etc/snort/snort.conf\r\n\r\nRemember, if snort doesn’t start you can find error logs from the /var/log/messages file. You can find answer of all problems from this file.\r\n\r\nNote: If you remember, i said that in the /usr/local/etc/snort/snort.conf configuration file the limit of log file will reach 32Mb it will create new one. This is not in rotation and one time will take all space in your file system. Before set to cron and remove log files we must detect handle time approximately. For example interval for 15 days was normal for me.\r\n\r\nAdd the following lines to the /etc/crontab file, for clean snort  alert logs each 15 days:\r\n# Snort Alert logs clean\r\n*       6       *       *       *       root    /usr/bin/find /var/log/snort/ -type f -mtime +15 -exec rm -f {} \\; >/dev/null 2>&1\r\n\r\nAnd now connect Snort from Barnyard2 to MySQL database:\r\nBarnyard takes alerts from Snort logs and insert them to MySQL database:\r\ncd /usr/ports/security/barnyard2          # Go to the port folder\r\nmake config                               # Choose needed modules\r\nbarnyard2-port\r\nmake install\r\n\r\nBut if we want, we can also start barnyard with different username. For that you must do the following steps:\r\n## Add to the system user ‘barny’ with the 999 UID and GID.\r\nUsername: barny\r\nFull name: Barnyard user for Snort\r\nUid (Leave empty for default): 999\r\nLogin group [barny]:\r\nLogin group is barny. Invite barny into other groups? []:\r\nLogin class [default]:\r\nShell (sh csh tcsh nologin) [sh]: nologin\r\nHome directory [/home/barny]:\r\nHome directory permissions (Leave empty for default):\r\nUse password-based authentication? [yes]: no\r\nLock out the account after creation? [no]:\r\nUsername   : barny\r\nPassword   : <disabled>\r\nFull Name  : Barnyard user for Snort\r\nUid        : 999\r\nClass      :\r\nGroups     : barny\r\nHome       : /home/barny\r\nHome Mode  :\r\nShell      : /usr/sbin/nologin\r\nLocked     : no\r\nOK? (yes/no): yes\r\n\r\nmkdir /var/log/barnyard2                  # Create log folder for Barnyard2.\r\ntouch /var/log/snort/barnyard2.waldo      # Create the file.\r\n\r\n## Set access for Snort and barny for both logs.\r\nchown -R barny:snort /var/log/barnyard2/\r\nchmod -R 770 /var/log/barnyard2/\r\nchown -R barny:snort /var/log/snort\r\nchmod -R 770 /var/log/snort\r\ntouch /var/log/snortsnort.log\r\nchown snort:barny /var/log/snortsnort.log\r\n\r\nWe also add the line below to the cron schedule to work each 1 minute. Because when each log is created, this will take owning of root user and snort group.\r\n# Snort logs chown\r\n*/1     *       *       *       *       root    chown -R barny:snort /var/log/snort\r\n\r\n/etc/rc.d/cron restart        # Restart the service\r\n\r\nCreate database for barnyard:\r\nmysql -u root –pfreebsd             # Connect to MySQL with root username and create database, login and password. Also grant access.\r\nCREATE DATABASE snort;\r\nGRANT ALL PRIVILEGES ON snort.* TO ''snort''@''localhost'' IDENTIFIED BY ''freebsd'';\r\nFLUSH PRIVILEGES;\r\n\r\nCreate structure for Barnyard in MySQL:\r\nmysql -u snort -pfreebsd snort < /usr/local/share/examples/barnyard2/create_mysql\r\n\r\nour configuration file /usr/local/etc/barnyard2.conf will be as follows:\r\nconfig utc\r\nconfig reference_file:      /usr/local/etc/snort/reference.config\r\nconfig classification_file: /usr/local/etc/snort/classification.config\r\nconfig gen_file:            /usr/local/etc/snort/gen-msg.map\r\nconfig sid_file:            /usr/local/etc/snort/sid-msg.map\r\n\r\nconfig event_cache_size: 4096\r\nconfig logdir: /var/log/barnyard2\r\n\r\noutput alert_fast\r\nconfig hostname:   IT_VPS\r\nconfig interface:  em0\r\nconfig alert_with_interface_name\r\nconfig daemon\r\n\r\nconfig set_gid: 999\r\nconfig set_uid: 999\r\nconfig waldo_file: /var/log/snort/barnyard2.waldo\r\n\r\ninput unified2\r\noutput alert_fast\r\noutput log_tcpdump: tcpdump.log\r\n\r\n# To connect Barnyard to our database configuration line is as follows\r\noutput database: log, mysql, user=snort password=freebsd dbname=snort host=localhost\r\n\r\n# And this line is for connecting to SnortSAM and when its time will come we will delete comment before line\r\n#Here it means connect to the localhost and port 777 with 123 password\r\n#output alert_fwsam: localhost:777/123\r\n\r\nCheck the starting of Barnyard:\r\n/usr/local/bin/barnyard2 -c /usr/local/etc/barnyard2.conf -d /var/log/snort -f snort.log\r\n\r\necho ''barnyard2_enable="YES"''>> /etc/rc.conf                # Add Barnyard to startup\r\n\r\nbarnyard2_flags="-d /var/log/snort -f snort.log -w /var/log/snort/barnyard2.waldo"\r\nbarnyard2_conf="/usr/local/etc/barnyard2.conf"\r\n\r\n/usr/local/etc/rc.d/barnyard2 start       # Start the Barnyard\r\n\r\nps -ax | grep barnyard | grep -v grep     # Check PID of Barnyard\r\n1413  -  Rs     1:54.97 /usr/local/bin/barnyard2 -d /var/log/snort -f snort.log -w /var/log/snort/barnyard2.waldo -c /usr/local/etc/barnyard2.conf -D\r\n\r\nRemember, if snort doesn’t start you can find error logs from the /var/log/messages file. You can find answer of all problems from this file. The successful result from /var/log/messages file is as follows:\r\nOct 28 03:25:44 snort barnyard2[1439]: database: compiled support for (mysql)\r\nOct 28 03:25:44 snort barnyard2[1439]: database: configured to use mysql\r\nOct 28 03:25:44 snort barnyard2[1439]: database: schema version = 107\r\nOct 28 03:25:44 snort barnyard2[1439]: database:           host = localhost\r\nOct 28 03:25:44 snort barnyard2[1439]: database:           user = snort\r\nOct 28 03:25:44 snort barnyard2[1439]: database:  database name = snort\r\nOct 28 03:25:44 snort barnyard2[1439]: database:    sensor name = IT_VPS:em0\r\nOct 28 03:25:44 snort barnyard2[1439]: database:      sensor id = 1\r\nOct 28 03:25:44 snort barnyard2[1439]: database:     sensor cid = 3\r\nOct 28 03:25:44 snort barnyard2[1439]: database:  data encoding = hex\r\nOct 28 03:25:44 snort barnyard2[1439]: database:   detail level = full\r\nOct 28 03:25:44 snort barnyard2[1439]: database:     ignore_bpf = no\r\nOct 28 03:25:44 snort barnyard2[1439]: database: using the “log” facility\r\nOct 28 03:25:44 snort barnyard2[1439]:\r\nOct 28 03:25:44 snort barnyard2[1439]:         –== Initialization Complete ==–\r\nOct 28 03:25:44 snort barnyard2[1439]: Barnyard2 initialization completed successfully (pid=1439)\r\nOct 28 03:25:44 snort barnyard2[1439]: Using waldo file ‘/var/log/snort/barnyard2.waldo’:     spool directory = /var/log/snort     spool filebase  = snort.log     time_stamp      = 1414447356     record_idx      = 0\r\nOct 28 03:25:44 snort barnyard2[1439]: Opened spool file ‘/var/log/snort/snort.log.1414447356’\r\nOct 28 03:25:44 snort barnyard2[1439]: Closing spool file ‘/var/log/snort/snort.log.1414447356’. Read 0 records\r\nOct 28 03:25:44 snort barnyard2[1439]: Opened spool file ‘/var/log/snort/snort.log.1414451087’\r\nOct 28 03:25:47 snort barnyard2[1439]: Waiting for new data\r\n\r\nNote: Usually this problem appears when restart MySQL and Barnyard2 have not access to own PID file. We must restart Barnyard when we restart MySQL. Just delete PID files as it is shown below and start Barnyard again.\r\n\r\nrm /var/run//barnyard2_em0.pid                  # Delete PID files\r\nrm /var/run//barnyard2_em0.pid.lck\r\n\r\nAnd now let’s install Snorby WEB interface:\r\nSnorby was written in Ruby-Rails programing language. And for it we must install ruby1.9: because Snorby needs only it(This will not work with 2.0 version):\r\ncd /usr/ports/converters/wkhtmltopdf            # snorby needs this port\r\nmake install                                    # install\r\n\r\nAfter installation it will write binary files as pathes below:\r\n/usr/local/bin/wkhtmltoimage\r\n/usr/local/bin/wkhtmltopdf\r\n\r\necho "RUBY_DEFAULT_VER=1.9" >> /etc/make.conf   # Set Ruby version before\r\necho "WITHOUT_X11=yes" >> /etc/make.conf        # We don’t need X.\r\n\r\ncd /usr/ports/lang/ruby19                 # Go to the port\r\nmake config                               # Choose needed modules\r\nruby-port\r\nmake install                              # Install\r\n\r\ncd /usr/ports/devel/ruby-gems/            # Go to the port\r\nmake config                               # Choose needed modules\r\nruby-gems-port\r\nmake install                              # Install\r\n\r\nAfter installation binary file will be written to the  /usr/local/bin/gem19 path.\r\ncd /usr/ports/devel/git       # Go to the GIT port\r\nmake config                   # Choose needed modules\r\ngit-port\r\nmake install                  # Install\r\n\r\nContinue installation:\r\n/usr/local/bin/gem install prawn –no-rdoc –no-ri\r\n/usr/local/bin/gem install rake -v 0.8.7 –no-rdoc –no-ri\r\n/usr/local/bin/gem install rails –no-rdoc –no-ri\r\n/usr/local/bin/gem install mysql –no-rdoc –no-ri\r\n/usr/local/bin/gem install passenger –no-rdoc –no-ri\r\n/usr/local/bin/passenger-install-apache2-module -a\r\n\r\nAfter the installation the following lines in the /usr/local/etc/apache24/httpd.conf configuration file add after the last line of LoadModule directive:\r\nLoadModule passenger_module /usr/local/lib/ruby/gems/1.9/gems/passenger-4.0.53/buildout/apache2/mod_passenger.so\r\n        <IfModule mod_passenger.c>\r\n        PassengerRoot /usr/local/lib/ruby/gems/1.9/gems/passenger-4.0.53\r\n        PassengerDefaultRuby /usr/local/bin/ruby19\r\n</IfModule>\r\n\r\n/usr/local/etc/rc.d/apache24 restart      # Restart the Daemon for commit changes.\r\n\r\nmkdir /usr/local/www/snorby         # Create Public_HTML folder for Snorby\r\ncd /usr/local/www/snorby            # Go to the folder\r\n\r\nwget https://github.com/Snorby/snorby/archive/v2.6.2.tar.gz # Download snorby archived file\r\n\r\ntar -zxf v2.6.2.tar.gz        # Extract the file\r\ncp -R snorby-2.6.2/* .        # Copy the files to snorby folder\r\nrm -rf snorby-2.6.2.tar.gz    # Remove the zip file\r\nrm -rf snorby-2.6.2           # Remove extracted fodler\r\nchown -R www:www /usr/local/www/snorby # Change owner and group of folder to www\r\n\r\nbundle pack             # This command will download needed packets to the /usr/local/www/snorby/vendor/cache\r\nbundle install --path vendor/cache  # Install downloaded packets\r\n\r\nThen copy the configuration files from sample to original:\r\ncp /usr/local/www/snorby/config/snorby_config.yml.example /usr/local/www/snorby/config/snorby_config.yml\r\ncp /usr/local/www/snorby/config/database.yml.example /usr/local/www/snorby/config/database.yml\r\n\r\nNote: I detected a problem here. When Snorby tried to start it was  warning snort database structure in MySQL. And that is why I had to create a new snorby database and connect to the barnyard.\r\nmysql -uroot –pfreebsd  # Login to the MySQL and create the database\r\nCREATE DATABASE snorby; # Create the database\r\n\r\n# Grant access to database with username, host and password\r\nGRANT ALL PRIVILEGES ON snorby.* TO ''snorby''@''localhost'' IDENTIFIED BY ''freebsd'';\r\nFLUSH PRIVILEGES;\r\n\r\nChange the /usr/local/www/snorby/config/snorby_config.yml configuration file as follows:\r\nproduction:\r\n  domain: ''localhost:3000''\r\n  wkhtmltopdf: /usr/local/bin/wkhtmltopdf\r\n  ssl: false\r\n  mailer_sender: ''snorby@snorby.org''\r\n  geoip_uri: "http://geolite.maxmind.com/download/geoip/database/GeoLiteCountry/GeoIP.dat.gz"\r\n  rules:\r\n    - "/usr/local/etc/snort/rules"\r\n    - "/usr/local/etc/snort/so_rules"\r\n    - "/usr/local/etc/snort/preproc_rules"\r\n  authentication_mode: database\r\n  time_zone: ''AZST''\r\ndevelopment:\r\n  domain: localhost:3000\r\n  wkhtmltopdf: /Users/mephux/.rvm/gems/ruby-1.9.2-p0/bin/wkhtmltopdf\r\n  ssl: false\r\n  mailer_sender: ''snorby@snorby.org''\r\n  geoip_uri: "http://geolite.maxmind.com/download/geoip/database/GeoLiteCountry/GeoIP.dat.gz"\r\n  rules:\r\n    - "/Users/mephux/.snort/rules"\r\n    - "/Users/mephux/.snort/so_rules"\r\n  authentication_mode: database\r\ntest:\r\n  domain: localhost:3000\r\n  wkhtmltopdf: /usr/local/bin/wkhtmltopdf\r\n  mailer_sender: ''snorby@snorby.org''\r\n  geoip_uri: "http://geolite.maxmind.com/download/geoip/database/GeoLiteCountry/GeoIP.dat.gz"\r\n  authentication_mode: database\r\n\r\nThe configuration file /usr/local/www/snorby/config/database.yml for database will be as follows:\r\nsnorby: &snorby\r\n  adapter: mysql\r\n  username: snorby\r\n  password: "freebsd" # Example: password: "s3cr3tsauce"\r\n  host: localhost\r\n\r\ndevelopment:\r\n  database: snorby\r\n  <<: *snorby\r\n\r\ntest:\r\n  database: snorby\r\n  <<: *snorby\r\n\r\nproduction:\r\n  database: snorby\r\n  <<: *snorby\r\n\r\nIf you want to configure mail, you can change the /usr/local/www/snorby/config/initializers/mail_config.rb file as lines below. For example configuration of Gmail.\r\n# Snorby Mail Configuration\r\n\r\n# #\r\n# Gmail Example:\r\n#\r\n# ActionMailer::Base.delivery_method = :smtp\r\n# ActionMailer::Base.smtp_settings = {\r\n#   :address              => “smtp.gmail.com”,\r\n#   :port                 => 587,\r\n#   :domain               => “snorby.org”,\r\n#   :user_name            => “snorby”,\r\n#   :password             => “snorby”,\r\n#   :authentication       => “plain”,\r\n#   :enable_starttls_auto => true\r\n# }\r\n\r\n# #\r\n# Sendmail Example:\r\n#\r\n# ActionMailer::Base.delivery_method = :sendmail\r\n# ActionMailer::Base.sendmail_settings = {\r\n#   :location => ‘/usr/sbin/sendmail’,\r\n#   :arguments => ‘-i -t’\r\nActionMailer::Base.perform_deliveries = true\r\nActionMailer::Base.raise_delivery_errors = true\r\n# Mail.register_interceptor(DevelopmentMailInterceptor) if Rails.env.development?\r\n\r\nAt the end start.\r\ncd /usr/local/www/snorby            # Enter the address and start\r\nbundle exec rake snorby:setup\r\nJammit Warning: Asset compression disabled — Java unavailable.\r\nNo time_zone specified in snorby_config.yml; detected time_zone: Asia/Baku\r\n97c2e4924cd06a2ebec95759dfce4292e70c0dd816c90f8eb80b7c7c8da3fe56b6f702fa548170d3dd2bf30842970e1                                                                                                      0903a1039f2f09b6819ca26043989b049\r\n# Don’t look at error because we have already created the database.\r\nERROR 1007 (HY000) at line 1: Can’t create database ‘snorby’; database exists\r\n[datamapper] Finished auto_upgrade! for :default repository ‘snorby’\r\n[~] Adding `index_timestamp_cid_sid` index to the event table\r\n[~] Adding `index_caches_ran_at` index to the caches table\r\n[~] Adding `id` to the event table\r\n[~] Building `aggregated_events` database view\r\n[~] Building `events_with_join` database view\r\n* Removing old jobs\r\n* Starting the Snorby worker process.\r\nJammit Warning: Asset compression disabled — Java unavailable.\r\n* Adding jobs to the queue\r\n\r\nchown -R www:www /usr/local/www/snorby # Change owner and group to www\r\n\r\nbundle exec rails server -e production          # We can start Bu emr ile production server from console by this command. But we will do it from apache.\r\n\r\nBefore we will create for that virtualhost in apache configuration and then will add needed port for listen to apache configuration file:\r\n\r\nAdd the lines below to /usr/local/domen/snorby.atl.az file:\r\n<VirtualHost *:3000>\r\n        ServerAdmin webmaster@localhost\r\n        DocumentRoot "/usr/local/www/snorby/public"\r\n        ServerName snorby.atl.az\r\n        ServerAlias www.snorby.atl.az\r\n        <Directory "/usr/local/www/snorby/public">\r\n                AllowOverride all\r\n                Options -MultiViews\r\n                Require all granted\r\n        </Directory>\r\n</VirtualHost>\r\n\r\nIn the /usr/local/etc/apache24/httpd.conf configuration file, after Listen 80 directive add new listen directive to start snorby as below:\r\nListen 80\r\nListen 3000\r\n\r\n/usr/local/etc/rc.d/apache24 restart      # At the end restart the web server\r\n\r\nAt last go to this link http://snorby.atl.az:3000/users/login get the page below:\r\nSnorby-login-page\r\n\r\nUsername: snorby@snorby.org\r\nPass: snorby\r\nIf login successfully the following page will be shown:\r\nSnorby-Statistic-page\r\n\r\nBefore all you must change the password:\r\nSnorby-settings-page\r\nAnd we see that there is nothing in the logs. Because, as I said before snorby didn’t want to work without creating database and so I had to create a database named snorby, in order to connect and write there. And that is why we can’t see the barnyard’s logs. And it means that now in real there is no connection between snorby and snort in database. Let’s fix it.  Login to MySQL and add needed access:\r\n\r\nmysql -u root -pfreebsd             # Login to MySQL with root account and grant access to barnyard for snorby database. After flush privileges for commit changes.\r\nGRANT ALL PRIVILEGES ON snorby.* TO ''snort''@''localhost'' IDENTIFIED BY ''freebsd'';\r\nFLUSH PRIVILEGES;\r\n\r\nAlso in the /usr/local/etc/barnyard2.conf configuration file change the line below to connect to the snorby database:\r\noutput database: log, mysql, user=snort password=freebsd dbname=snorby host=localhost\r\n\r\n/usr/local/etc/rc.d/barnyard2 stop  # Stop the barnyard\r\n/usr/local/etc/rc.d/barnyard2 start # Start the barnyard\r\n\r\nAnalyze the /var/log/messages file and if we see the lines below, then all our works is success:\r\nOct 28 14:39:18 snort barnyard2[92208]: Barnyard2 initialization completed successfully (pid=92208\r\nOct 28 14:39:18 snort barnyard2[92208]: Using waldo file ‘/var/log/snort/barnyard2.waldo’:     spool directory = /var/log/snort     spool filebase  = snort.log     time_stamp      = 1414451087     record_idx      = 25412\r\nOct 28 14:39:18 snort barnyard2[92208]: Opened spool file ‘/var/log/snort/snort.log.1414451087’\r\nOct 28 14:39:20 snort barnyard2[92208]: Waiting for new data\r\n\r\nYou must wait minimum 10 minute, because barnyard must write all events to mysql database.\r\n\r\nAfter success the statistics will be shown as below:\r\nSnorby-after-success-statistics\r\n\r\nIf you will see the error Snorby worker is not currently working you can fix this as below:\r\n\r\nWhat it is for:\r\n\r\nWhen snorby starts one process in background which starts snorby in production mode. You can see about this at the end of first page of https://snorby.org/ official page and the lines that I showed below.\r\nbundle exec rails server -e production\r\nruby script/delayed_job start RAILS_ENV=production\r\n\r\nYou can use the following command to start from CLI:\r\n/usr/local/bin/ruby /usr/local/www/snorby/script/delayed_job start\r\n\r\nTo automate our work we will use expect language and for using it we must install it:\r\ncd /usr/ports/lang/expect  # Go to the port\r\nmake install               # install\r\n\r\nAdd the following lines to this /root/run_snorby_WP file:\r\n#!/usr/local/bin/expect -f\r\nset timeout 1000\r\nspawn /bin/ps aux\r\nexpect "delayed_job" {\r\n     exit\r\n}\r\ncd /usr/local/www/snorby\r\nspawn /usr/local/bin/ruby script/delayed_job start\r\nexpect "ERROR: there is already one or more instance(s) of the program running" {\r\n     cd /usr/local/www/snorby\r\n     system /usr/local/bin/ruby script/delayed_job restart\r\n}\r\nexit\r\n\r\nchmod 700 /root/run_snorby_WP   # Doing executable for root user\r\nexpect /root/run_snorby_WP      # With this command you can run from CLI to test it\r\n\r\nFor kill you can use command below:\r\nkill `ps aux | grep -v "grep" | grep delayed_job | awk ''{ print $2 }''`\r\n\r\nAdd cron schedule to check work each 15 minutes and automatic work after reboot:\r\n*/15 *    *    *    *    root /usr/local/bin/expect -f /root/run_snorby_WP >/dev/null 2>&1\r\n@reboot root    /usr/local/bin/expect -f /root/run_snorby_WP >/dev/null 2>&1\r\n\r\nBut Snorby can work unstable and can’t update itself. Then we will do it manually from the link as it is shown following screenshot More Options -> Force Cache Update.\r\nsnorby-cache-fix\r\n\r\nNote: Because of the fault below your database can be widen illogically and we don’t need this.\r\nThe only way to solve it is to TRUNCATE all coloums with big numerals.\r\nstream5: TCP session without 3-way handshake\r\n\r\nAt last it is time Snortsam\r\nWe can say that Snortsam has no documentation and it is in dead position.The only solution way is its communication with barnyard.You can read about it from the README.snortsam documentation.\r\n\r\ncd /usr/ports/security/snortsam/          # Go to the port folder\r\nmake config                               # Don’t forget to select IPFW module and don’t check debug cause it will not compile\r\nsnortsam-port\r\nmake install                              # install\r\n\r\nAfter installation copy all all sample files to the original:\r\ncp /usr/local/etc/snortsam/country-rootservers.conf.sample /usr/local/etc/snortsam/country-rootservers.conf\r\ncp /usr/local/etc/snortsam/rootservers.cfg.sample /usr/local/etc/snortsam/rootservers.cfg\r\ncp /usr/local/etc/snortsam/snortsam.conf.sample /usr/local/etc/snortsam/snortsam.conf\r\n\r\nThe configuration /usr/local/etc/snortsam/snortsam.conf file will be consist of the following lines:\r\ndefaultkey 123                # 123 is the key which we use to talk with barnyard\r\nport 777                      # Listen on the port 777\r\naccept 127.0.0.1, 123         # Allow to access from the 127.0.0.1 IP address with the 123 password\r\nlogfile /var/log/snortsam.log # Set the log file\r\nloglevel 3                    # Log level debug for detail information\r\nfwexec /sbin/ipfw             # Used firewall IPFW\r\nipfw2 em0 1 2                 # Listen on em0 and write rules to table 1 and 2\r\ndaemon                        # Start in daemon mode for working automatically\r\n#include /usr/local/etc/snortsam/rootservers.cfg\r\n#include /usr/local/etc/snortsam/country-rootservers.conf\r\n\r\ntouch /var/log/snortsam.log   # Create log file to see logs\r\n\r\nWe create /etc/ipfw.conf configuration file for our firewall and write the following lines in it:\r\nipfw add 00010 deny ip from any to "table(1)" via em0\r\nipfw add 00011 deny ip from "table(2)" to any via em0\r\nipfw add 00200 deny ip from any to 127.0.0.0/8\r\nipfw add 00300 deny ip from 127.0.0.0/8 to any\r\nipfw add 65000 allow ip from any to any\r\n\r\nAdd the following lines to /etc/rc.conf file for working after reboot:\r\nfirewall_enable="YES"\r\nfirewall_type="UNKNOWN"\r\nfirewall_script="/etc/ipfw.conf"\r\ngateway_enable="YES"\r\n\r\nIn the configuration /boot/loader.conf file will be the following lines or you must add IPDIVERT and IPFW options to your kernel and recompile to work IPFW firewall:\r\nipdivert_load="YES"\r\nipfw_load="YES"\r\nhw.usb.no_pf=1\r\n\r\nAt the end we delete the comment that was in the last line of  /usr/local/etc/barnyard2.conf configuration file and then restart it in order to connect to snortsam:\r\noutput alert_fwsam: 127.0.0.1:777/123\r\n\r\nAdd the following lines to /etc/rc.conf configuration file for working snortsam after rebooting:\r\nsnortsam_enable="YES"\r\nsnortsam_conf="/usr/local/etc/snortsam/snortsam.conf"\r\n\r\n/usr/local/etc/rc.d/snortsam start  # We start Daemon and successful result must be as follows.\r\nSnortSam, v 2.70.\r\nCopyright (c) 2001-2009 Frank Knobbe <frank@knobbe.us>. All rights reserved.\r\n\r\nPlugin ‘fwsam’: v 2.5, by Frank Knobbe\r\nPlugin ‘fwexec’: v 2.7, by Frank Knobbe\r\nPlugin ‘pix’: v 2.9, by Frank Knobbe\r\nPlugin ‘ciscoacl’: v 2.12, by Ali Basel <alib@sabanciuniv.edu>\r\nPlugin ‘cisconullroute’: v 2.5, by Frank Knobbe\r\nPlugin ‘cisconullroute2’: v 2.2, by Wouter de Jong <maddog2k@maddog2k.net>\r\nPlugin ‘netscreen’: v 2.10, by Frank Knobbe\r\nPlugin ‘ipf’: v 2.16, by Erik Sneep <erik@webflex.nl>\r\nPlugin ‘pf2’: v 3.3, by Olaf Schreck <chakl@syscall.de>\r\nPlugin ‘ipfw2’: v 2.4, by Robert Rolfe <rob@wehostwebpages.com>\r\nPlugin ‘watchguard’: v 2.7, by Thomas Maier <thomas.maier@arcos.de>\r\n\r\n Plugin ’email’: v 2.12, by Frank Knobbe\r\nPlugin ’email-blocks-only’: v 2.12, by Frank Knobbe\r\nPlugin ‘snmpinterfacedown’: v 2.3, by Ali BASEL <ali@basel.name.tr>\r\nPlugin ‘forward’: v 2.8, by Frank Knobbe\r\nParsing config file /usr/local/etc/snortsam/snortsam.conf…\r\nLinking plugin ‘fwexec’…\r\nLinking plugin ‘ipfw2’…\r\nChecking for existing state file “/var/db/snortsam.state”.\r\nFound. Reading state file.\r\nStarting to listen for Snort alerts.\r\n\r\ncat /var/log/snortsam.log     # We must see the following result in the log file\r\n2014/10/28, 22:27:34, -, 3, fwexec, fwexec: Will call ''/sbin/ipfw'' to initiate blocks.\r\n2014/10/28, 22:27:34, -, 1, snortsam, Starting to listen for Snort alerts.\r\n\r\nAt the end we reboot server and can see the following lines in the /var/log/snortsam.log file where connection from localhost coming to snortsam:\r\n2014/10/28, 22:42:25, 127.0.0.1, 3, snortsam, Accepted connection from 127.0.0.1.\r\n2014/10/28, 22:42:25, 127.0.0.1, 3, snortsam, Adding sensor 127.0.0.1 to list.\r\n\r\nIf you do all steps exactly, after reboot everything will work. Because when I did everything worked. But, in any way if snortsam will not start, add the following lines to the /etc/crontab  file and remove snortsam lines from /etc/rc.conf file. It will be enough.\r\n@reboot /usr/local/sbin/snortsam  >/dev/null 2>&1\r\n\r\nFor testing create rule and test our IPS\r\nmkdir /usr/local/etc/snort/rules/local.rules    # Create folder for rule\r\n\r\nAdd the following lines to the /usr/local/etc/snort/rules/local.rules/test.rules file:\r\nalert tcp any any -> 88.8.81.134 80 (msg:"TEST block remoteserver port 80"; sid:5555501; rev:1; priority:1;)\r\nalert tcp any any -> 88.8.81.134 443 (msg:"TEST block remoteserver port 443"; sid:5555502; rev:1; priority:1;)\r\n\r\nchown -R snort:snort /usr/local/etc/snort # Change owner and group to snort\r\n\r\nrev – It is the version of the rule, if we don’t write it, the rule won’t work.\r\npriority 1 – It is the priority of the rule, it will be red.\r\nSID(Snort IDENTIFIER) – And just with it comes block commant to IPFW.\r\n\r\nIt means that we block access for 10 minutes from any of source IP address and ports to our server IP 88.8.81.134 and ports 80,443(If we write here dst it will be block for destination). If you noticed exactly, you saw every rule had it own SID.\r\n\r\nWe have to add these SIDs with similar syntax to the /usr/local/etc/sid-block.map file to block source which are match the rules. sid-block.map file is roughly defined in barnyard2 code that it must be in the same address with its configuration file. It means if barnyard2.conf configuration file is located in /usr/local/etc/ address, sid-block.map file has to be in the same address.\r\n\r\nThen we create /usr/local/etc/sid-block.map named file in the folder that barnyard.conf is located and add the following lines:\r\n5555501: src, 10 min # Here we write SID, traffic direction and block time.\r\n5555502: src, 10 min          # Here we write SID, traffic direction and block time\r\n\r\nExplain the syntax from sid-block.map file:\r\nsid     – This is Snort ID which is communicating with Snort SAM rule\r\n\r\nwho     – src(source), dst(destination)\r\nIP address which will block with snort ID\r\n\r\nhow   – In, out, src, dest, either, both, this, conn, connection\r\nIt is not required parameter which says to SnortSAM that block any coming packets, In and Out from this host.\r\n\r\ntime  – Blocking time with seconds. (It is possible ‘days‘, ‘months‘, ‘weeks‘,\r\n‘years‘, ‘minutes‘, ‘seconds‘, ‘hours‘. Alternative way with writing\r\n0(always) or PERManent, INFinite, ALWAYS you can block it for ever\r\n(Be careful with this!).\r\n\r\nExamples:\r\n1487: src[either],15min;\r\n1292: dst[in], 2 days 4 hours\r\n1638: src, 1 hour\r\n\r\nWe add the following line to the configuration file /usr/local/etc/snort/snort.conf where include is located, to start the rules:\r\ninclude $RULE_PATH/local.rules/test.rules\r\n\r\nThen we restart Snort and BarnYard. Or we reboot server for test all startups.\r\n/usr/local/etc/rc.d/snort restart\r\n/usr/local/etc/rc.d/barnyard2 restart\r\n\r\nThen we test by attacking to server where snort is located with our following script(Add lines below to https-check.sh file):\r\n# cat https-check.sh\r\n#!/usr/local/bin/bash\r\n\r\nif ! [ -x “$(type -P ab)” ]; then\r\necho “ERROR: script requires apache bench”\r\necho “For FreeBSD and friends get it with ‘pkg_add -r apache22?”\r\necho “If you have it, perhaps you don’t have permissions to run it, try ‘sudo $(basename $0)''”\r\nexit 1\r\nfi\r\n\r\nif [ “$#” -ne “4” ]; then\r\necho “ERROR: script needs four arguments, where:”\r\necho\r\necho “1. Number of times to repeat test (e.g. 10)”\r\necho “2. Total number of requests per run (e.g. 100)”\r\necho “3. How many requests to make at once (e.g. 50)”\r\necho “4. URL of the site to test (e.g. http://yoursite.org/)”\r\necho\r\necho “Example:”\r\necho ”  $(basename $0) 10 100 50 http://yoursite.org/”\r\necho\r\necho “The above will send 100 GET requests (50 at a time) to http://yoursite.org. The test will be repeated 10 times.”\r\nexit 1\r\nelse\r\nruns=$1\r\nnumber=$2\r\nconcurrency=$3\r\nsite=$4\r\nfi\r\n\r\nlog=ab.$(echo $site | sed -r ‘s|https?://||;s|/$||;s|/|_|g;’).log\r\n\r\nif [ -f $log ]; then\r\necho removing $log\r\nrm $log\r\nfi\r\n\r\necho “==================================================================”\r\necho ” Results”\r\necho “==================================================================”\r\necho ” site ………. $site”\r\necho ” requests …… $number”\r\necho ” concurrency … $concurrency”\r\necho “——————————————————————”\r\n\r\nfor run in $(seq 1 $runs); do\r\nab -c$concurrency -n$number $site >> $log\r\necho -e ” run $run: \\t $(grep “^Requests per second” $log | tail -1 | awk ‘{print$4}’) reqs/sec”\r\ndone\r\n\r\navg=$(awk -v runs=$runs ‘/^Requests per second/ {sum+=$4; avg=sum/runs} END {print avg}’ $log)\r\n\r\necho “——————————————————————”\r\necho ” average ……. $avg requests/sec”\r\necho\r\necho “see $log for details”\r\n\r\nExecute this script and use for attack:\r\n# chmod +x https-check.sh\r\n# ./https.sh 3 4000 500 http://snort.server.ip/\r\napr_socket_recv: Connection reset by peer (54)\r\nrun 1:           reqs/sec\r\napr_socket_recv: Connection reset by peer (54)\r\nrun 2:           reqs/sec\r\napr_socket_connect(): Permission denied (13)\r\n\r\nWe will see in Snort log file that Snort send the requests to Barnyard and Barnyard insert these requests to MySQL database. After complete this insert it will connect to SnortSAM and send alert. SnortSAM get this alert, and send request to IPFW2 for adding IP address of coming source to 1st and 2nd table:\r\ntail -n 10 /var/log/mysql.log\r\n1 Query     INSERT INTO opt (sid,cid,optid,opt_proto,opt_code,opt_len,opt_data) VALUES (1,1185659,0,6,2,2,’05B4?)\r\n1 Query     INSERT INTO iphdr (sid, cid, ip_src, ip_dst, ip_ver, ip_hlen, ip_tos, ip_len, ip_id, ip_flags, ip_off,ip_ttl, ip_proto, ip_csum) VALUES (1,1185659,423182146,1578389894,4,5,0,48,766,0,0,124,6,62388)\r\n1 Query     COMMIT\r\n1 Query     BEGIN\r\n1 Query     INSERT INTO event (sid,cid,signature,timestamp) VALUES (1, 1185660, 509, ‘2014-10-29 14:04:07?)\r\n1 Query     INSERT INTO tcphdr (sid, cid, tcp_sport, tcp_dport, tcp_seq, tcp_ack, tcp_off, tcp_res, tcp_flags, tcp_win, tcp_csum, tcp_urp) VALUES (1,1185660,3072,80,4200216406,2152351244,7,0,2,8192,41671,0)\r\n1 Query     INSERT INTO opt (sid,cid,optid,opt_proto,opt_code,opt_len,opt_data) VALUES (1,1185660,0,6,2,2,’05B4’)\r\n1 Query     INSERT INTO iphdr (sid, cid, ip_src, ip_dst, ip_ver, ip_hlen, ip_tos, ip_len, ip_id, ip_flags, ip_off,ip_ttl, ip_proto, ip_csum) VALUES (1,1185660,241434114,1578389894,4,5,0,48,766,0,0,124,6,16330)\r\n1 Query     COMMIT\r\n1 Query     BEGIN\r\n\r\nWe see in SnortSAM log that it added information about blocking to IP address sourced 99.45.57.58 to IPFW tables:\r\ntail -f /var/log/snortsam.log\r\n2014/10/29, 02:23:21, 127.0.0.1, 2, snortsam, Blocking host 99.45.57.58 completely for 600 seconds (Sig_ID: 5555501).\r\n2014/10/29, 02:23:21, -, 3, ipfw2, Info: Command “/sbin/ipfw table 1 add 99.45.57.58/32;/sbin/ipfw table 2 add 99.45.57.58/32” Executed Successfully\r\n\r\nWe look at the rules in 1st and 2nd tables of IPFW:\r\nipfw -i table 1 list | grep 99.45.57.58/32\r\n99.45.57.58/32 0.0.0.0\r\nipfw -i table 2 list | grep 99.45.57.58/32\r\n99.45.57.58/32 0.0.0.0\r\n\r\ntail -f /var/log/barnyard2/barnyard2.alert            # Also we can see in the log file of barnyard that it send alert to SnortSAM.\r\n10/29-02:23:20.735311  [**] [1:5555501:1] <em0> Snort Alert [1:5555501:1] [**] [Classification ID: 0] [Priority ID: 1] {TCP} 99.45.57.58:1024 -> 88.8.81.134:80\r\n\r\nFor example we can see in our Snort server the attack of different host to the server which IPS is located:\r\nsnorby-alert-page\r\n\r\nBut the /usr/local/etc/sid-block.map file’s filling automatically, working dynamically is not a day’s work. But we can do it something.For doing this it was used a lot of regex syntax and let’s explain them before:\r\n\r\nWe match the Regex lines:\r\n^[^\\#] – # Started with the symbol\r\n.*sid: – Any symbol on the left and any word with sid word on the right:\r\n(.[0-9]*[0-9]\\) – () the inner is which we want to catch, but [0-9]*[0-9]  any ordered amount of numbers.\r\n.* – At the end wildcard for the sed\r\ns// – The operator which writes it \\1?:” “src,” “30min”/p”\r\n\\1 – that we catched before\r\n“:” “src,” “30min” – It is the text that we connect to, if here will be double brackets ” ” it means space\r\n\\p – Go to the new line\r\n\r\nThen we write pathes of files with spaces. Remember that it is not needed to write all rules for src-a gore yazilmali deyil. In my case this is just an example.\r\n\r\nResult:\r\nsed -n "\\%^[^\\#].*sid:\\(.[0-9]*[0-9]\\).*% s//\\1":" "src," "30min"/p" /usr/local/etc/snort/rules/backdoor.rules /usr/local/etc/snort/rules/bad-traffic.rules /usr/local/etc/snort/rules/black_list.rules /usr/local/etc/snort/rules/botnet-cnc.rules /usr/local/etc/snort/rules/ddos.rules /usr/local/etc/snort/rules/exploit-kit.rules /usr/local/etc/snort/rules/exploit.rules /usr/local/etc/snort/rules/blacklist.rules /usr/local/etc/snort/rules/malware-backdoor.rules  /usr/local/etc/snort/rules/malware-cnc.rules /usr/local/etc/snort/rules/malware-other.rules /usr/local/etc/snort/rules/malware-tools.rules /usr/local/etc/snort/rules/phishing-spam.rules /usr/local/etc/snort/rules/policy-spam.rules /usr/local/etc/snort/rules/spyware-put.rules /usr/local/etc/snort/rules/virus.rules /usr/local/etc/snort/rules/web-attacks.rules /usr/local/etc/snort/rules/local.rules/test.rules >  /usr/local/etc/sid-block.map\r\n\r\n/usr/local/etc/rc.d/barnyard2 restart     # Restart the Barnyard daemon.\r\n\r\nAutomatize all things!\r\nUpdate rules from Snort site and after block!\r\nOinkMaster is busy and that is why we will do it next!\r\n\r\nFirst we must create rules for src and dst block!\r\n/tmp/test/blocksrc.rules – The file for src block\r\n/tmp/test/blockdst.rules – The file for dst blocks\r\n\r\nWe need 2 sed command:\r\nDelete old file and add content for src from blocksrc.rules file.\r\nsed -n "\\%^[^\\#].*sid:\\(.[0-9]*[0-9]\\).*% s//\\1":" "src," "30min"/p" /tmp/test/blocksrc.rules >  /tmp/test/sid-block.map\r\n\r\nDelete old file and add content for dst from blockdst.rules file.\r\nsed -n "\\%^[^\\#].*sid:\\(.[0-9]*[0-9]\\).*% s//\\1":" "dst," "30min"/p" /tmp/test/blockdst.rules > /tmp/test/sbd_tmp.map\r\n\r\nThe blocking of first file wasn’t done succesfully with sed , and that is why we join two files with the 3rd command.\r\ncat /tmp/test/sbd_tmp.map >> /tmp/test/sid-block.map\r\n\r\nAt the end we add the following line to /etc/crontab file after OinkMaster finishing its work, for Barnyard collecting blocked files and restarting it.\r\n30    5     *     *     *     root  /usr/local/bin/oinkmaster -o /usr/local/etc/snort/rules/&&/usr/bin/sed -n "\\%^[^\\#].*sid:\\(.[0-9]*[0-9]\\).*% s//\\1":" "src," "30min"/p" /tmp/test/blocksrc.rules >  /tmp/test/sid-block.map&&/usr/bin/sed -n "\\%^[^\\#].*sid:\\(.[0-9]*[0-9]\\).*% s//\\1":" "dst," "30min"/p" /tmp/test/blockdst.rules > /tmp/test/sbd_tmp.map&&/bin/cat /tmp/test/sbd_tmp.map >> /tmp/test/sid-block.map&&/bin/ps aux | /usr/bin/grep -v "grep" | /usr/bin/grep /usr/local/bin/barnyard2 | /usr/bin/awk ''{print $2}'' | /usr/bin/xargs kill&&/usr/local/bin/barnyard2 -Dn -c /usr/local/etc/barnyard2.conf -d /var/log/snort -f snort.log >/dev/null 2>&1\r\n\r\nIt is needed resources for this system, because,there can be emergency, Snort can create big traffic.  It is true that snort will write them quickly to its files. But Barnyard2 and MySQL can take them for an hour!\r\n\r\nFor example snort generated 310MB traffic for 2 minutes. In my virtual machine was 1 CPU, 4 core and 4GB RAM, but I waited insert from barnyard2 to MySQL more than an hour.\r\n\r\nUsed sources: http://www.itcooky.com/', '2016-01-17 00:00:00', 1, NULL, 'FreeBSD Snort IPS', 5, 1);
INSERT INTO `Article` (`id`, `content`, `pubDate`, `published`, `subTitle`, `title`, `author_id`, `category_id`) VALUES
(10, 'On December 28, 2015, the free software world lost of one its smartest programmers and software engineers, Ian Murdock. Ian was most well known for his founding and creation of one of the most respected Linux distributions to date, Debian.\r\n\r\nian-murdock-bio\r\n\r\nThrough Ian’s creation of Debian, the Linux operating system has gained a reputation for being one of the most solid, reliable and versatile Linux operating systems for the server and desktop sectors.\r\n\r\n\r\n \r\nDebian has provided the basis for many Linux based operating systems, including the world’s most popular Linux system, Ubuntu.\r\n\r\nDebian development continues today through the volunteer efforts of thousands of software developers and engineers. Whilst Linus Torvalds is often considered the grandfather of Linux, Debian is equally considered the grandfather of Linux based operating systems.\r\n\r\nThe tireless work Ian Murdock put into Debian and other projects earned him the respect that he deserved.\r\n\r\nIn January 2006 Ian’s hard work led him to a role as Chief Technology Officer (CTO) with the Free Standards Group, which eventually evolved into the Linux Foundation. Ian continued his role as CTO until the following year of March 2007 where he was employed at Sun Microsystems to lead Project Indiana. When Sun Microsystems merged with software giant Oracle, Ian resigned from the company.\r\n\r\nFrom 2011-2015 Ian was employed by Salesforce Marketing Cloud, until in November 2015 he joined Docker Inc. His role with Docker was short-lived, when on December 30, 2015, Docker announced his tragic passing.\r\n\r\nWhilst specific circumstances surrounding his passing have not been officially released, there are indications that Ian Murdock had taken his own life. Absolutely tragic and deeply saddening for Ian’s family, friends, colleagues and all of the free and open-source software community.\r\n\r\nIt’s important to remember the legacy that Ian left behind, through his work as a free and open-source software developer and engineer. More specifically, Ian will always be remembered for the founding and creation of the world’s most loved and respected Linux operating systems, Debian. May you rest in peace Ian Murdock, you will be sorely missed.\r\n\r\nAs a sign of our respect to Ian, today we finish our tribute by publishing the Debian Manifesto written by Ian Murdock in 1994.\r\n\r\nA.1 What is Debian Linux?\r\n\r\nDebian Linux is a brand-new kind of Linux distribution. Rather than being developed by one isolated individual or group, as other distributions of Linux have been developed in the past, Debian is being developed openly in the spirit of Linux and GNU. The primary purpose of the Debian project is to finally create a distribution that lives up to the Linux name. Debian is being carefully and conscientiously put together and will be maintained and supported with similar care.\r\n\r\nIt is also an attempt to create a non-commercial distribution that will be able to effectively compete in the commercial market. It will eventually be distributed by The Free Software Foundation on CD-ROM, and The Debian Linux Association will offer the distribution on floppy disk and tape along with printed manuals, technical support and other end-user essentials. All of the above will be available at little more than cost, and the excess will be put toward further development of free software for all users. Such distribution is essential to the success of the Linux operating system in the commercial market, and it must be done by organizations in a position to successfully advance and advocate free software without the pressure of profits or returns.\r\n\r\nA.2 Why is Debian being constructed?\r\n\r\nDistributions are essential to the future of Linux. Essentially, they eliminate the need for the user to locate, download, compile, install and integrate a fairly large number of essential tools to assemble a working Linux system. Instead, the burden of system construction is placed on the distribution creator, whose work can be shared with thousands of other users. Almost all users of Linux will get their first taste of it through a distribution, and most users will continue to use a distribution for the sake of convenience even after they are familiar with the operating system. Thus, distributions play a very important role indeed.\r\n\r\nDespite their obvious importance, distributions have attracted little attention from developers. There is a simple reason for this: they are neither easy nor glamorous to construct and require a great deal of ongoing effort from the creator to keep the distribution bug-free and up-to-date. It is one thing to put together a system from scratch; it is quite another to ensure that the system is easy for others to install, is installable and usable under a wide variety of hardware configurations, contains software that others will find useful, and is updated when the components themselves are improved.\r\n\r\nMany distributions have started out as fairly good systems, but as time passes attention to maintaining the distribution becomes a secondary concern. A case-in-point is the Softlanding Linux System (better known as SLS). It is quite possibly the most bug-ridden and badly maintained Linux distribution available; unfortunately, it is also quite possibly the most popular. It is, without question, the distribution that attracts the most attention from the many commercial "distributors" of Linux that have surfaced to capitalize on the growing popularity of the operating system.\r\n\r\nThis is a bad combination indeed, as most people who obtain Linux from these "distributors" receive a bug-ridden and badly maintained Linux distribution. As if this wasn''t bad enough, these "distributors" have a disturbing tendency to misleadingly advertise non-functional or extremely unstable "features" of their product. Combine this with the fact that the buyers will, of course, expect the product to live up to its advertisement and the fact that many may believe it to be a commercial operating system (there is also a tendency not to mention that Linux is free nor that it is distributed under the GNU General Public License). To top it all off, these "distributors" are actually making enough money from their effort to justify buying larger advertisements in more magazines; it is the classic example of unacceptable behavior being rewarded by those who simply do not know any better. Clearly something needs to be done to remedy the situation.\r\n\r\nA.3 How will Debian attempt to put an end to these problems?\r\n\r\nThe Debian design process is open to ensure that the system is of the highest quality and that it reflects the needs of the user community. By involving others with a wide range of abilities and backgrounds, Debian is able to be developed in a modular fashion. Its components are of high quality because those with expertise in a certain area are given the opportunity to construct or maintain the individual components of Debian involving that area. Involving others also ensures that valuable suggestions for improvement can be incorporated into the distribution during its development; thus, a distribution is created based on the needs and wants of the users rather than the needs and wants of the constructor. It is very difficult for one individual or small group to anticipate these needs and wants in advance without direct input from others.\r\n\r\nDebian Linux will also be distributed on physical media by the Free Software Foundation and the Debian Linux Association. This provides Debian to users without access to the Internet or FTP and additionally makes products and services such as printed manuals and technical support available to all users of the system. In this way, Debian may be used by many more individuals and organizations than is otherwise possible, the focus will be on providing a first-class product and not on profits or returns, and the margin from the products and services provided may be used to improve the software itself for all users whether they paid to obtain it or not.\r\n\r\nThe Free Software Foundation plays an extremely important role in the future of Debian. By the simple fact that they will be distributing it, a message is sent to the world that Linux is not a commercial product and that it never should be, but that this does not mean that Linux will never be able to compete commercially. For those of you who disagree, I challenge you to rationalize the success of GNU Emacs and GCC, which are not commercial software but which have had quite an impact on the commercial market regardless of that fact.\r\n\r\nThe time has come to concentrate on the future of Linux rather than on the destructive goal of enriching oneself at the expense of the entire Linux community and its future. The development and distribution of Debian may not be the answer to the problems that I have outlined in the Manifesto, but I hope that it will at least attract enough attention to these problems to allow them to be solved.', '2016-01-04 00:00:00', 1, NULL, 'Tribute to Debian Founder, Ian Murdock', 6, 3);

-- --------------------------------------------------------

--
-- Contenu de la table `Author`
--

INSERT INTO `Author` (`id`, `Admin`, `email`, `password`, `firstName`, `lastName`, `url`) VALUES
(1, 1, 'khamlichi.mohamed@gmail.com', 'a', 'Mohammad', 'el Khamlichi', NULL),
(2, 0, 'mohammad.varmazyar@fake.com', 'a', 'Mohammad', 'Varmazyar', NULL),
(3, 0, 'hossein.heydari@fake.com', 'a', 'Hossein', 'Heydari', NULL),
(4, 0, 'rajneesh.upadhyay@fake.com', 'a', 'Rajneesh', 'Upadhyay', 'linuxtutes.com'),
(5, 0, 'jamal.shahverdiev@fake.com', 'a', 'jamal', 'shahverdiev', 'unixmen.com/author/jamal/'),
(6, 0, 'cjones@freedompublishersunion.com', 'a', 'Chris', 'Jones', 'TheMuldyZone.net');

-- --------------------------------------------------------

--
-- Contenu de la table `Category`
--

INSERT INTO `Category` (`id`, `name`, `url`) VALUES
(1, 'Server', 'server'),
(2, 'Desktop', 'desktop'),
(3, 'Misc', 'misc'),
(4, 'Inutile', 'useless');

-- --------------------------------------------------------

--
-- Contenu de la table `Comment`
--

INSERT INTO `Comment` (`id`, `content`, `email`, `name`, `pubDate`, `validated`, `article_id`) VALUES
(1, 'azertyuiopârticle1C2', NULL, NULL, '2016-02-17 00:00:00', 1, 1),
(2, 'azertyuiopârticle1C1', NULL, NULL, '2016-02-03 00:00:00', 1, 1),
(3, 'azertyuiopârticle1C3', NULL, NULL, '2016-02-12 00:00:00', 0, 1),
(4, 'azertyuiopârticle1C4', NULL, NULL, '2016-02-26 00:00:00', 0, 1),
(5, 'azertyuiopârticle2', NULL, NULL, '2016-02-02 00:00:00', 0, 2),
(6, 'azertyuiopârticle5', NULL, NULL, '2016-02-27 00:00:00', 0, 5),
(7, 'azertyuiopârticle6c1', NULL, NULL, '2016-02-05 00:00:00', 0, 6),
(8, 'azertyuiopârticle6c2', NULL, NULL, '2016-02-03 00:00:00', 0, 6);

--
-- Index pour les tables exportées
--

--
-- Index pour la table `Article`
--
ALTER TABLE `Article`
  ADD PRIMARY KEY (`id`),
  ADD KEY `FK_i83utkpqpts0yrsy4ydqocrj1` (`author_id`),
  ADD KEY `FK_mscvyqw7t3thah18jfpd4ehm1` (`category_id`);

--
-- Index pour la table `Author`
--
ALTER TABLE `Author`
  ADD PRIMARY KEY (`id`);

--
-- Index pour la table `Category`
--
ALTER TABLE `Category`
  ADD PRIMARY KEY (`id`);

--
-- Index pour la table `Comment`
--
ALTER TABLE `Comment`
  ADD PRIMARY KEY (`id`),
  ADD KEY `FK_qwylmq9xjkhn6as6u91b94y9o` (`article_id`);

--
-- AUTO_INCREMENT pour les tables exportées
--

--
-- AUTO_INCREMENT pour la table `Article`
--
ALTER TABLE `Article`
  MODIFY `id` bigint(20) NOT NULL AUTO_INCREMENT,AUTO_INCREMENT=11;
--
-- AUTO_INCREMENT pour la table `Author`
--
ALTER TABLE `Author`
  MODIFY `id` bigint(20) NOT NULL AUTO_INCREMENT,AUTO_INCREMENT=7;
--
-- AUTO_INCREMENT pour la table `Category`
--
ALTER TABLE `Category`
  MODIFY `id` bigint(20) NOT NULL AUTO_INCREMENT,AUTO_INCREMENT=5;
--
-- AUTO_INCREMENT pour la table `Comment`
--
ALTER TABLE `Comment`
  MODIFY `id` bigint(20) NOT NULL AUTO_INCREMENT,AUTO_INCREMENT=9;
--
-- Contraintes pour les tables exportées
--
--
-- Contraintes pour la table `Article`
--
ALTER TABLE `Article`
  ADD CONSTRAINT `FK_i83utkpqpts0yrsy4ydqocrj1` FOREIGN KEY (`author_id`) REFERENCES `Author` (`id`),
  ADD CONSTRAINT `FK_mscvyqw7t3thah18jfpd4ehm1` FOREIGN KEY (`category_id`) REFERENCES `Category` (`id`);

--
-- Contraintes pour la table `Comment`
--
ALTER TABLE `Comment`
  ADD CONSTRAINT `FK_qwylmq9xjkhn6as6u91b94y9o` FOREIGN KEY (`article_id`) REFERENCES `Article` (`id`);
SET FOREIGN_KEY_CHECKS=1;

/*!40101 SET CHARACTER_SET_CLIENT=@OLD_CHARACTER_SET_CLIENT */;
/*!40101 SET CHARACTER_SET_RESULTS=@OLD_CHARACTER_SET_RESULTS */;
/*!40101 SET COLLATION_CONNECTION=@OLD_COLLATION_CONNECTION */;
